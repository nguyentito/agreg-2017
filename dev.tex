\documentclass[a4paper, 11pt]{article}

% Math symbols, notation, etc.
% Apparently, must be loaded earlier than mathspec?
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{amsthm}
\usepackage{tikz-cd}

% Locale/encoding with XeTeX: UTF-8 by default, use fontspec
\usepackage{unicode-math}
\usepackage[frenchb]{babel}
\usepackage{csquotes} % guillemets

% TeX Gyre Pagella = URW Palladio (free Palatino) extended
\setmainfont[Mapping=tex-text]{TeX Gyre Pagella}
\setmathfont{Asana Math}

% Other
\usepackage{fullpage}
%\usepackage{enumerate}
%\usepackage{graphicx}

% Macros de Jill-Jênn
\def\A{{\cal{A}}}
\def\F{\mathbb{F}}
\def\Z{\mathbb{Z}}
\def\N{\mathbb{N}}
\def\Q{\mathbb{Q}}
\def\U{\mathbb{U}}
\def\K{\mathbb{K}}
\def\P{\mathbb{P}}
\def\R{\mathbb{R}}
\def\C{\mathbb{C}}
\def\L{{\cal{L}}}
\def\S{{\cal{S}}}
\def\V{{\cal{V}}}
\def\T{{\cal{T}}}
\def\O{{\cal{O}}}
\def\Fs{{\cal{F}}}
\def\Ps{{\cal{P}}}
\def\Cf{{\cal{C}}}
\def\M{\mathcal{M}}
\def\MnK{{\cal M}_n(\K)}
\def\Tr{\textnormal{Tr}}
\def\Sp{\textnormal{Sp}}
\def\Re{\textnormal{Re}}
\def\Vect{\textnormal{Vect}}
\def\car{\textnormal{car}}
\def\pgcd{\textnormal{pgcd}}
\def\ppcm{\textnormal{ppcm}}
\def\Sigmap{\mathfrak{S}}
\def\prog{\texttt{prog}}

% Ajout personnel
\def\E{\mathbb{E}}
\def\Var{\textnormal{Var}}
\def\Ker{\textnormal{Ker}}
\def\Indic{\mathbb{1}}
\def\GL{\mathrm{GL}}
\def\SL{\mathrm{SL}}
\def\PSL{\mathrm{PSL}}
\def\Aut{\mathrm{Aut}}
\def\Vol{\mathrm{Vol}}
\def\Diag{\mathrm{Diag}}

\newtheorem*{definition}{Définition}
\newtheorem*{example}{Exemple}
\newtheorem*{proposition}{Proposition}
\newtheorem*{theorem}{Théorème}
\newtheorem*{application}{Application}
\newtheorem*{algo}{Algorithme}
\newtheorem*{lemma}{Lemme}
\newtheorem*{remark}{Remarque}
\newtheorem*{corollary}{Corollaire}

\begin{document}

\title{Mes développements d'agrég de math(-info)}
\author{Nguyễn Lê Thành Dũng\\(ENS Ulm, département informatique, promo 2012)}
\date{Préparation à l'agrégation de l'ENS Paris-Saclay, 2016--2017}
\maketitle

\tableofcontents

\newpage

\section{Algèbre/géométrie et analyse}

\subsection{Dualité lagrangienne et extrema liés en optimisation convexe}

On montre ici un théorème fondamental en recherche opérationnelle, variante du
théorème des extrema liés où :
\begin{itemize}
\item on a des multiplicateurs de Lagrange \emph{positifs} correspondant à des
  contraintes d'\emph{inégalité} (on ne pourra donc pas invoquer les
  sous-variétés) ;
\item les conditions nécessaires du premier ordre sont également
  \emph{suffisantes} grâce à la convexité.
\end{itemize}
Soient $f,g_1,\ldots,g_k : \R^n \to \R$ des fonctions \emph{convexes}.
On considère le problème de minimisation
\[ p = \inf_{x \in F} f(x) \qquad F = \left\{ x \in \R^n \mid
  g_i(x) \leq 0,\; i = 1,\ldots,k \right\} \]
(Vocabulaire : $f$ est la \emph{fonction objectif}, les $g_i$ sont des
\emph{contraintes}, $F$ est l'ensemble des \emph{solutions réalisables}).

On appelle \emph{condition de Slater} l'existence d'un $x_0 \in \R^n$
\emph{strictement réalisable}, c'est-à-dire tel que $g_i(x_0) < 0$ pour tout
$i$.

\begin{theorem}[Karush--Kuhn--Tucker]
  On suppose ici que $f, g_1, \ldots, g_k$ sont $\Cf^1$, et que la condition de
  Slater est vérifiée. Alors pour tout $x \in \F$, $f(x) = p$ si et seulement
  s'il existe $\mu_1, \ldots, \mu_k \geq 0$ tels que
  \[ \nabla f(x) + \sum_{i=0}^k \mu_i \nabla g_i(x) = 0 \quad \text{et} \quad
    \mu_i g_i(x) = 0\; \forall i
  \]
\end{theorem}

Afin de montrer cela, introduisons le \emph{lagrangien} $\L : \R^n \times
\R_+^k$ et le problème dual associé :
\[ \L(x, \mu) = f(x) + \sum_{i=1}^k \mu_i g_i(x) \qquad
  d = \sup_{\mu \in \R_+^k} \inf_{x \in \R^n} \L(x,\mu) \]

\begin{remark} $\displaystyle p = \inf_{x \in \R^n} \sup_{\mu \in \R_+^k}
  \L(x,\mu)$.
\end{remark}
\begin{proof}
  En effet, si $x \not\in F$, alors il existe $i$ tel que $g_i(x) > 0$.
  $\L(x,(0, \ldots, \mu_i, \ldots, 0)) \to +\infty$ quand $\mu_i \to
  +\infty$. Donc $\sup_{\mu \in \R_+^k} \L(x,\mu) = +\infty$ dès que $x \not\in
  F$, et si $x \in F$, le sup est atteint pour $\mu = 0$ soit $\L(x,\mu) =
  f(x)$.
\end{proof}
\begin{corollary}[Dualité faible]
  $d \leq p$.
\end{corollary}
\begin{proof}
  Il s'agit simplement de voir que pour tout $x, \mu$,
  \[ \inf_{y} \L(y, \mu) \leq \L(x,\mu) \leq \sup_{\nu} \L(x,\nu) \]
  puis de prendre le sup sur $\mu$ à gauche et l'inf sur $x$ à droite.
\end{proof}

\begin{theorem}[Dualité forte]
  On suppose seulement que $f, g_1, \ldots, g_k$, et que la condition de Slater
  est satisfaite. Alors $p = d$ et le supremum dual est atteint.
\end{theorem}
\begin{proof}
  Si $p = -\infty$, la dualité faible permet de conclure directement que $d =
  -\infty$.
  
  Sinon, il suffit de montrer $p \leq d$, donc de trouver $\mu_1, \ldots, \mu_k
  \geq 0$ tels que pour tout $x \in \R^n$, $\L(x,\mu) \geq p$.

  Posons $A, B \subset \R^{k+1}$ définis par
  \[ A = \left\{ (y_1, \ldots, y_k, z) \mid \exists x \in \R^n\,/\,
    y_i \geq g_i(x),\; z \geq f(x) \right\}
    \qquad B = \left\{ (y_1, \ldots, y_k, z) \mid y_i < 0,\;z < p \right\}\]

  Si $(y_1,\ldots,y_k,z) \in A \cap B$, alors il existe $x$ tel que $g_i(x) \leq
  y_i < 0$ pour tout $x$, donc $x \in F$, et $f(x) \leq z < p$. C'est impossible
  par définition de $p$. Ainsi, $A$ et $B$ sont disjoints, avec $A$ ouvert.
  
  Donc il existe un hyperplan séparateur\footnote{Il faut faire attention aux
    hypothèses topologiques de la version de Hahn-Banach qu'on utilise ici.
    Sinon, on pourrait invoquer le théorème de séparation des convexes en
    dimension finie de Minkowski, qui demande seulement que les deux convexes
    soient disjoints.} i.e. une forme linéaire $\varphi$ telle que $\varphi(a) \geq
  \varphi(b)$ pour tout $a \in A$ et $b \in B$. En coordonnées, $\varphi$ s'écrit
  \[ \varphi(y_1, \ldots, y_k, z) = \mu_1 y_1 + \ldots + \mu_k y_k + \nu z \]
  
  En prenant $a = (g_1(x), \ldots, g_k(x), f(x))$, et $b = (0, \ldots, 0, p) \in
  \overline{B}$, on a
  \[ \sum_{i=1}^k \mu_i g_i(x) + \nu f(x) \geq \nu p \]
  Quand $g_i(x) < 0$ (il existe un tel $x$ par hypothèse), on a $\nu f(x) > \nu
  p$, d'où $\nu > 0$. En divisant par $\nu$, on a finalement :
  $\L(x, \mu_1/\nu, \ldots, \mu_k/\nu) \geq p$.
\end{proof}

Supposons maintenant que $f, g_1, \ldots, g_k$ sont $\Cf^1$. 
\begin{proof}[Les conditions KKT sont nécessaires]
  Fixons $\mu_1, \ldots, \mu_k$ maximisant le dual : $\inf_x \L(x, \mu) = d =
  p$. Soit $x$ tel que $f(x) = p$. Alors
  \[ f(x) = p = d \leq \L(x, \mu) = f(x) + \sum_{i=0}^k \mu_i g_i(x) \] Comme
  $g_i(x) \leq 0$ et $\mu_i \geq 0$ pour tout $i$, ce qui entraîne l'inégalité
  réciproque, on a en fait $\mu_i g_i(x) = 0$ pour tout $i$. Ainsi, en $x$,
  $\L(-, \mu)$ atteint la valeur $d$ qui est son minimum, son gradient s'annule
  donc. Ceci donne immédiatement la condition au premier ordre.
\end{proof}

\begin{proof}[Les conditions KKT sont suffisantes]
Soient $x \in F$ et $\mu \in \R_+^k$ vérifiant ces conditions. Alors, comme
$\L(-,\mu)$ est convexe, ses points stationnaires sont ses minima globaux, donc
elle atteint son minimum en $x$. Comme $\mu_i g_i(x) = 0$ pour tout $i$, le
lagrangien vaut $f(x)$ :
\[ f(x) = \L(x,\mu) = \inf_{x'} \L(x',\mu) \leq \sup_{\mu'} \inf_{x'}
  \L(x',\mu') = p
\]
donc $x$ minimise bien $f$ sur $F$.
\end{proof}

\paragraph{Ci-dessous, une tentative de prouver autrement la dualité forte…}
comme corollaire du \emph{théorème du minimax de Sion}. L'intérêt étant de voir
un lien entre condition de Slater et compacité.

On a besoin comme hypothèse supplémentaire que $d > -\infty$ (comment s'en
passer ?). On rappelle qu'un sup de fonctions semi-continues inférieurement
l'est, et qu'une telle fonction admet un minimum sur tout compact.

Fixons $R > 0$ et posons $\bar{B}_R = \bar{B}(x_0,R)$, qui est convexe compact.
Soit
\[ p_R = \min_{x \in \bar{B}_R} \sup_{\mu \in \R_+^k} \L(x,\mu)
       = \sup_{\mu \in \R_+^k} \min_{x \in \bar{B}_R} \L(x,\mu) \]
l'égalité résultant du théorème du minimax.

La première expression donne $p_R = \min_{x \in F \cap \bar{B}_R} f(x)$
(l'ensemble étant non vide puisque $x_0$ y est).

D'autre part, par la seconde expression, $p_R \geq d$. Comme $x_0$ est
strictement réalisable, quand $\|\mu\| \to +\infty$ en restant dans $\R_+^k$,
$\L(x_0, \mu) \to +\infty$ . Il existe donc un compact $K \subset \R_+^k$ tel
que $\forall \mu \in \R_+^k \setminus K,\; \L(x_0, \mu) < d \leq p_R$ (et $K$
est indépendant de $R$, c'est important !). D'où
\[ p_R = \max_{\mu \in K} \min_{x \in \bar{B}_R} \L(x,\mu) =
  \min_{x \in \bar{B}_R} \max_{\mu \in K} \L(x,\mu) \]
Quand $R \to +\infty$, on trouve
\[ \inf_{x \in F} f(x) = \inf_{x \in \R^n} \max_{\mu \in K} \L(x,\mu) 
  = \max_{\mu \in K} \inf_{x \in \R^n} \L(x,\mu)  \]
où, cette fois-ci, on a utilisé la compacité de $K$ pour appliquer le théorème
du minimax à $-\L$ ! Tout ceci fonctionnant encore avec n'importe quel convexe
compact $K' \supseteq K$, en épuisant $\R_+^k$ avec des compacts, on a
finalement $p = d$, et de plus, on sait qu'une solution duale optimale $\mu^*$
existe.

Question ouverte : peut-on montrer $d > -\infty$ sans utiliser un argument
d'hyperplan séparateur ?


\newpage

\subsection{Fonction tangente et permutations zigzag}

Cf. Richard P. Stanley, \emph{A Survey of Alternating Permutations}. Le terme
\enquote{permutation alternante} pouvant induire en confusion avec le groupe
alterné, nous parlerons ici de \emph{permutation zigzag}.

\begin{theorem}[Désiré André]
La série génératrice des permutations haut-bas est $tan(z)+sec(z)$.
\end{theorem}

Merci à Paul Melotti, c'est fait dans son PDF.

\subsection{Méthode de Kaczmarz}

Référence : à trouver.

Soient $A \in \GL_n(\R)$ et $b \in \R^n$. On veut résoudre $Ax = b$
itérativement. Pour cela, on pose $(l_1, \ldots, l_n)$ les lignes de $A$, et
$p_i$ le projecteur orthogonal sur l'hyperplan affine $H_i$ d'équation $l_ix =
b_i$ ($i \in \{1, \ldots, n\}$). À partir de $x_0 \in \R^n$ quelconque, on
définit par récurrence
\[ x_{k+1} = p_{(k+1\, \textnormal{mod}\, n)}(x_k). \]

Soit $x^* = A^{-1}b$ l'unique solution. $\bigcap_{i=1}^n H_i = \{x^*\}$, et
c'est l'unique point fixe commun de $p_1, \ldots, p_n$. En posant $y_k = x_k -
x^*$, on voit que
\[ y_{k+1} = p_i(x_k) - x^* = p_i(x_k) - p_i(x^*) = \pi_i(y_k) \] où $\pi_i$ est
la partie linéaire de $p_i$, soit la projection orthogonale sur $\Ker(l_i)$.

Nous souhaitons maintenant montrer que $x_k \longrightarrow x^*$, soit $y_k
\longrightarrow 0$. Pour cela, on va montrer que $\|\Pi\| < 1$ où $\Pi = \pi_n
\circ \ldots \circ \pi_1$. Ensuite, comme $\|\pi_i\| = 1$, on aura $\|y_k\| \leq
\|\Pi\|^{\lfloor p/n \rfloor} \|y_0\|$, d'où convergence linéaire.

Soit $z \in \R^n$. On a $\|\pi_i(z)\| = \|z\|$ si et seulement si $\pi(z) = z$
soit $z \in \Ker(l_i)$, et $\|\pi_i(z)\| < \|z\|$ sinon (par théorème de
Pythagore…). Donc $\Pi(z) = z \Leftrightarrow z \in \bigcap_{i=1}^n \Ker(l_i) =
\{0\}$ (car $A \in \GL_n(\R)$) : pour tout $z \neq 0$, $\|\Pi(z)\| < \|z\|$.
Comme nous sommes en dimension finie, ceci implique que $\|\Pi\| < 1$ (par
compacité de la sphère unité).

\newpage

\section{Algèbre (et géométrie)}

\subsection{Points à distances impaires, avec le déterminant de Gram}

Le résultat suivant est tiré d'un petit article : \emph{Are there $n+2$ points
  in $E^n$ with odd integral distances}, Graham, Rothschild \& Straus. Il a été
posé comme exercice à l'oral de l'ENS Lyon en 2015. (Peut-être se trouve-t-il
dans l'un des Francinou--Gianella…)
\begin{theorem}
  Soit $n \in \N^*$. Il existe $n+2$ points distincts à distances entières
  impaires dans $\R^n$ si et seulement si $n+2 \equiv 0 \mod 16$.
\end{theorem}

La preuve originale utilise le \emph{déterminant de Cayley-Menger}, qui permet
de calculer le volume de simplexes et généralise ainsi la formule de Héron. On
trouvera des détails sur ce fameux déterminant dans le Zavidovique. Nous allons
utiliser ici le déterminant de Gram, plus connu, pour éviter des calculs avec
des opérations élémentaires sur les lignes et les colonnes.

\paragraph{Preuve du sens direct}

Soit $n \in \N$ et $x_0, \ldots, x_{n+1}$ des points dans $\R^n$ tels que pour
tout $i \neq j$, $\|x_i - x_j\| \in 2\Z + 1$. Quitte à translater, on peut
prendre $x_0 = 0$.

Notons $G = (\langle x_i, x_j \rangle)_{1 \leq i,j \leq n+1}$ la matrice de Gram
de $x_1, \ldots, x_{n+1}$, $J$ la matrice carrée de taille $n+1$ dont tous les
coefficients valent 1, et $A = (a_{ij})_{1 \leq i,j \leq n+1} = I+J$.

\begin{proposition}
  $\det G = 0$.
\end{proposition}
\begin{proof}
  Le déterminant de Gram d'une famille liée est toujours nul, et les $x_1,
  \ldots, x_{n+1}$ sont dans $\R^n$ donc sont liés. En effet, si $M$ est la
  matrice des $(x_i)$ dans une base orthonormale (de taille $n \times (n+1)$),
  alors $G = M^T M$ a un rang majoré par celui de $M$, qui est le rang de la
  famille de vecteurs.
\end{proof}

\begin{proposition}
  $\det A = n+2$.
\end{proposition}
\begin{proof}
  $J$ est de rang 1 donc a pour valeur propre 0 avec multiplicité $n$. On
  vérifie que $(1,\ldots,1)$ est vecteur propre pour la valeur propre $n+1$, ce
  qui achève de déterminer le spectre de $J$. Les valeurs propres de $A = I+J$
  sont donc $1, \ldots, 1, n+2$, leur produit vaut donc $n+2$.
\end{proof}

On va prouver $\det 2G \equiv \det A \mod 16$, ce qui suffira à conclure avec
les deux propositions ci-dessus. Pour cela, regardons ce qu'on peut dire sur
$2G$ modulo 16.

\begin{remark}
  Si $m$ est impair, $m^2 \equiv 1 \mod 8$ et $2m^2 \equiv 2 \mod 16$.
\end{remark}
\begin{proof}
  Facile à vérifier à la main ; le second résultat se déduit du premier, pas
  besoin d'examiner 8 classes de congruence.
\end{proof}

Ainsi, l'identité de polarisation $2 \langle x_i, x_j \rangle = \|x_i\|^2 +
\|x_j\|^2 - \|x_i - x_j\|^2$ entraîne que les coefficients non diagonaux de $2G$
sont congrus à 1 modulo 8 (remarquer que $\|x_i\|^2 = \|x_i - x_0\|^2$ est bien
le carré d'un nombre impair). Quant aux coefficients diagonaux, de la forme
$2\|x_i\|^2$, ils sont congrus à 2 modulo 16. Ainsi
\[ 2G \equiv A + B \mod 16, \qquad B = (b_{ij})_{1 \leq i,j \leq n+1} \in
  S_{n+1}(\Z),\; b_{ii} = 0,\; b_{ij} \in \{0,8\} \]
Donc $\det 2G \equiv \det(A+B) \mod 16$ car le déterminant est un polynôme à
coefficients entiers en les coefficients de la matrice. Reste à prouver
$\det(A+B) \equiv \det A \mod 16$.

Écrivons la formule de Leibniz :
\[ \det(A+B) = \sum_{\sigma \in \Sigmap_{n+1}} \varepsilon(\sigma) T_\sigma,
  \quad T_\sigma = \prod_{i=1}^{n+1} (a_{i \sigma(i)} + b_{i \sigma(i)}) \]
$A+B$ étant une matrice symétrique, $T_\sigma = T_{\sigma^{-1}}$ pour tout
$\sigma \in \Sigmap_n$ (et en général $\varepsilon(\sigma) =
\varepsilon(\sigma^{-1})$), et
\[ T_\sigma \equiv \prod_{i=1}^{n+1} a_{i \sigma(i)} \mod 8 \quad \text{donc}
  \quad T_\sigma + T_{\sigma^{-1}} = 2 T_\sigma \equiv 2 \prod_{i=1}^{n+1} a_{i
    \sigma(i)} \mod 16. \]

On peut ainsi regrouper les termes de la somme dans $\det(A+B)$ par deux pour
montrer la congruence voulue… à l'exception des termes pour $\sigma =
\sigma^{-1}$, c'est à dire $\sigma$ involutif.

Fixons $\sigma$ une involution et développons $T$. Étudions les termes
comportant au moins un facteur $b_i$. S'il y en a deux, alors le terme est
divisible par 64, donc congru à 0 mod 16. Donc
\[ T_\sigma \equiv \prod_{i=1}^{n+1} a_{i \sigma(i)} + \sum_{i=1}^{n+1} t_i
  \mod 16 \qquad t_i = b_{i \sigma(i)} \prod_{j \neq i} a_{j \sigma(j)}
  \equiv 0 \mod 8 \]
Pour $i \in \{1, \ldots, n+1\}$, alors :
\begin{itemize}
\item si $i$ est un point fixe de $\sigma$, alors $b_{i \sigma(i)} = b_{ii} = 0$
  donc $t_i = 0$ ;
\item sinon, $\sigma$ transpose $i$ et $\sigma(i)$, et $t_i = t_{\sigma(i)}$,
  toujours par symétrie des matrices $A$ et $B$.
\end{itemize}
Finalement, on peut toujours regrouper les termes non nuls par deux, et obtenir
que
\[ T_\sigma \equiv \prod_{i=1}^{n+1} a_{i \sigma(i)} \mod 16 \]
En fin de compte, on a :
\[ \det(A+B) \equiv \sum_{\sigma \in \Sigmap_{n+1}} \varepsilon(\sigma)
  \prod_{i=1}^{n+1} a_{i \sigma(i)} \equiv \det A \mod 16 \]
ce qu'il fallait démontrer.

\paragraph{Preuve du sens réciproque}

Soit $n = 16m - 2$, $m \in \N^*$, plaçons-nous dans l'espace euclidien de
dimension $n$. Soit $H$ un hyperplan et $P_1, \ldots, P_n \in H$ les sommets
d'un simplexe régulier de centre $O$, avec $P_iP_j = n/2 = 8m-1$. On va rajouter
à cette famille deux points symétriques par rapport à $H$, $Q$ et $Q'$, de sorte
que le milieu de $[QQ']$ soit $O$. En prenant $QQ' = 4m - 1$, on peut montrer
que $QP_i = Q'P_i = 6m - 1$ pour tout $i$ : on a bel et bien $n+2$ points à
distances impaires.


\newpage


\subsection{Étude des automorphismes extérieurs de $\Sigmap_6$}

(Inspiré d'un billet de blog de David Madore.)

Supposons qu'on ait prouvé l'existence d'un automorphisme extérieur (voir à la
fin pour une construction). À quoi ressemble l'ensemble de ces automorphismes
extérieurs ? Peut-on les décrire tous, de façon combinatoire ? On va présenter
ici une description inspirée de celle faite par Sylvester vers 1844 ; au lieu de
parler de synthèmes, on utilisera des triples transpositions, qui sont la même
chose avec de la structure algébrique en plus.

Pour $x \in \{1, \ldots, 6\}$, on note $e(x) = (x\;y_1)\ldots(x\;y_5) \in
\Sigmap_6$ où $\{ y_1, \ldots, y_5 \} = \{1, \ldots, 6\}\setminus\{x\}$. Les
éléments la forme $e(x)$ sont appelés \emph{étoiles} et leur ensemble est noté
$E$. $e$ réalise une bijection canonique entre $\{1, \ldots, 6\}$ et $E$.

\begin{proposition}
  Toute famille de 5 transpositions distinctes ne commutant pas deux à deux est
  une étoile.
\end{proposition}
\begin{proof}
  Soit $\{\tau_1, \ldots, \tau_5\}$ une telle famille. $\tau_1$ et $\tau_2$ ne
  commutent pas donc $\tau_1 = (a\;b)$, $\tau_2 = (a\;c)$ avec $b \neq c$. De
  même $\tau_3 = (a'\;b')$, $\tau_4 = (a'\;c')$ avec $b' \neq c'$. $\tau_1$ et
  $\tau_3$ ne commutent pas non plus, et par l'absurde, si $a' = b$, alors on
  trouve que $\tau_2$ et $\tau_3$ commutent, contradiction. De même on ne peut
  pas avoir $a = b'$. Donc $a' = b$. Ainsi $\tau_1, \ldots, \tau_4$ ont un
  élément commun, et on montre facilement que $\tau_5$ aussi. Donc $\{\tau_1,
  \ldots, \tau_5\} = e(a) \in E$.
\end{proof}

\begin{corollary}
  Tout automorphisme qui envoie les transpositions sur des transpositions est
  intérieur.
\end{corollary}
\begin{proof}
  Soit $\varphi$ cet automorphisme. $\varphi(E) = E$, car \enquote{ne pas commuter}
  est préservé par automorphisme. Posons $g : x \mapsto e^{-1}(\varphi(e(x)))$, $g
  \in \Sigmap_6$, de sorte que $\varphi(e(x)) = e(g(x))$. Pour tout $a \neq b$,
  comme $\{(a\;b)\} = e(a) \cap e(b)$, on a $\varphi((a\;b)) = (g(a)\;g(b))$.
  $\varphi$ coïncide donc avec $\sigma \mapsto g\sigma g^{-1}$ sur les
  transpositions, qui engendrent $\Sigmap_6$, donc $\varphi$ est intérieur.
\end{proof}

\begin{proposition}
  Les automorphismes extérieurs de $\Sigmap_6$ échangent transpositions et
  triples transpositions.
\end{proposition}
\begin{proof}
  En effet, ce sont les seules classes de conjugaison d'ordre 2 dont les
  permutations ont pour signature $-1$. (Les automorphismes stabilisent
  $\mathfrak{A}_6$ car c'est le seul sous-groupe distingué non trivial.)
\end{proof}

On peut déjà en déduire que :

\begin{theorem}
  $\Aut(\Sigmap_6)/\mathrm{Int}(\Sigmap_6) \simeq \Z/2\Z$.
\end{theorem}
\begin{proof}
  Si $\varphi \in \Aut(\Sigmap_6) \setminus \mathrm{Int}(\Sigmap_6)$ et
  $\tau$ est une transposition, $\varphi(\tau)$ est une triple transposition et
  $\varphi^2(\tau)$ est une transposition. Ainsi, $\varphi^2 \in
  \mathrm{Int}(\Sigmap_6)$.
\end{proof}

En fait, on a même un produit semi-direct, mais on va s'intéresser à autre
chose.

Soit $F$ l'ensemble des familles de 5 triples transpositions qui ne commutent
pas, qu'on appellera \emph{co-étoiles}. Alors $\widehat{\varphi} : X \in E \mapsto
\varphi(X) \in F$ est une bijection.

\begin{proposition}
  Pour tout $g \in \Sigmap_6$, le diagramme suivant est commutatif :
  \begin{center}
  \begin{tikzcd}[column sep=large]
    \{1,\ldots,6\} \ar[d, "g"] \ar[r, "e"] & E \ar[d, "g(-)g^{-1}"]
    \ar[r, "\widehat{\varphi}"] & F \ar[d, "\varphi(g)(-)\varphi(g)^{-1}"] \\
    \{1,\ldots,6\} \ar[r, "e"] & E \ar[r, "\widehat{\varphi}"] & F
  \end{tikzcd}
  \end{center}
\end{proposition}
\begin{proof}
  Le carré de gauche signifie que la conjugaison sur les étoiles correspond à
  l'action sur les points, ce qu'on a déjà vu précédemment.
  
  Dans le carré de droite, on veut prouver que $\varphi(gXg^{-1}) =
  \varphi(g)\varphi(X)\varphi(g^{-1})$, où $X \in E$, donc $X \subset \Sigmap_6$. Mais
  c'est simplement la propriété de morphisme.
\end{proof}
On en déduit ce diagramme :
\begin{tikzcd}[column sep=large]
  \{1,\ldots,6\} \ar[d, "g"] \ar[r, "\widehat{\varphi^{-1}} \circ e"] 
  & F \ar[d, "g(-)g^{-1}"] \\
  \{1,\ldots,6\}\ar[r, "\widehat{\varphi^{-1}} \circ e"] & F 
\end{tikzcd}

Ainsi, tout automorphisme extérieur peut s'écrire sous la forme $\varphi(g)(x) =
f^{-1}(gf(x)g^{-1})$ avec $f : \{1, \ldots, 6\} \xrightarrow{\sim} F$ bijective.
Or, il y a autant d'automorphismes extérieurs qu'intérieurs
(puisque\footnote{Une utilisation du théorème de Lagrange se cache ici. Il faut
  bien voir que dans tout le développement, on utilise de la théorie des groupes
  pour éviter d'avoir à faire des dénombrements \enquote{à la main}…} le
quotient est $\Z/2\Z$), et $\mathrm{Int}(\Sigmap_6) \simeq \Sigmap_6$ (car on
peut retrouver la permutation d'origine à partir de la conjugaison en agissant
sur les étoiles !) : il y en a donc $6!$, autant que de bijections $\{1, \ldots,
6\} \xrightarrow{\sim} F$. Donc :
\begin{itemize}
\item pour tout $f$, le $\varphi$ ainsi défini est bien un automorphisme
  extérieur~;
\item pour tout $\varphi$, le $f$ qui convient est unique.
\end{itemize}

\paragraph{Conclusion} Tout automorphisme extérieur de $\Sigmap_6$ se factorise
en fait comme la composition de deux isomorphismes entre $\Sigmap_6$ et
$\Sigmap(F)$ : l'action par conjugaison de $\Sigmap_6$ sur $F$, et un transfert
de structure via une bijection. On a en fait un isomorphisme (qui n'est pas
endo) tout à fait canonique entre deux groupes de permutations sur 6 éléments,
mais dont les ensembles sous-jacents ne peuvent être identifiés que par un choix
non canonique de bijection, induisant alors un automorphisme extérieur.

En langage catégorique, on pourra résumer élégamment tout ceci en disant que
l'endofoncteur du groupoïde des ensembles de cardinal 6 qui a tout ensemble $X$
associe les co-étoiles de $\Sigmap(X)$ n'est pas naturellement isomorphe à
l'identité.


\paragraph{Une dernière remarque} Si deux triples transpositions partagent une
transpositions, elles commutent. (En effet, dans $\mathfrak{A}_4$, les doubles
transpositions et l'identité forment un sous-groupe isomorphe à $(\Z/2\Z)^2$,
qui est abélien.) Ainsi, les co-étoiles correspondent aux partitions du graphe
complet à 6 éléments en 5 triplets d'arêtes disjointes.

\paragraph{Annexe : construction d'un automorphisme extérieur de $\Sigmap_6$} La
construction présentée ici est tirée de Perrin, \emph{Cours d'algèbre},
proposition I.8.11.

\begin{remark}
  Il revient au même trouver un isomorphisme $\varphi : \Sigmap_6
  \xrightarrow{\sim} \Sigmap(E)$ qui n'est induit par aucune bijection
  $\{1,\ldots,6\} \to E$.
\end{remark}
(Et remarquons que plus haut, on a bien construit un tel isomorphisme, vers le
groupe de permutation des co-étoiles !)
\begin{proof}
  En effet, si $E = \{1,\ldots,6\}$, l'isomorphisme (automorphisme, donc)
  $\Sigmap_6 \to \Sigmap_6$ induit par une permutation $\sigma$ de
  $\{1,\ldots,6\}$ est exactement la conjugaison par $\sigma$ (penser à l'action
  de la conjugaison sur la décomposition en cycles disjoints). On retrouve ainsi
  les automorphismes intérieurs.

  Réciproquement, si $\varphi : \Sigmap_6 \to \Sigmap(E)$ n'est pas induit par une
  bijection, on a tout de même une égalité de cardinaux entraînant l'existence
  d'une bijection $f : \{1,\ldots,6\} \to E$, et alors quelle que soit $f$, on
  vérifie que $\varphi \circ \Sigmap(f)^{-1}$ est un automorphisme extérieur.
\end{proof}

Nous allons construire une telle bijection à partir du lemme ci-dessous.

\begin{lemma}
  Il existe un sous-groupe $H < \Sigmap_6$ d'indice 6 agissant transitivement
  sur $\{1,\ldots,6\}$ (pour l'action canonique de $\Sigmap_6$, bien entendu).
\end{lemma}
En fait, la situation est la suivante : dans $\Sigmap_n$ pour $n \neq 6$, de
tels sous-groupes n'existent pas et les sous-groupes d'indices $n$ sont ceux qui
stabilisent un point. Dans $\Sigmap_6$, on a aussi ceux qui stabilisent une
co-étoile. La vérification de tout ceci est laissée à la lectrice.

Dans le but d'éviter les raisonnements circulaires, une autre construction de
$H$ est présentée ci-dessous.
\begin{proof}
  Faisons agir $\Sigmap_5$ sur ses 5-Sylow par conjugaison. Ceci donne un
  morphisme de $\Sigmap_5$ dans le groupe des permutations de ces 5-Sylow, qui
  sont au nombre de 6. Le morphisme est injectif car son noyau ne peut être ni
  $\Sigmap_5$, ni $\mathfrak{A}_5$ : $\Sigmap_5$ s'identifie donc à un
  sous-groupe $H$ de $\Sigmap_6$, d'indice 6. La transitivité de l'action est
  garantie par les théorèmes de Sylow.
\end{proof}

Posons maintenant $E = \Sigmap_6/H$ l'ensemble des classes à gauche. $\Sigmap_6$
agit dessus par translation ce qui donne un morphisme $\varphi : \Sigmap_6 \to
\Sigmap(E)$. $\Ker(\varphi)$ est distingué dans $\Sigmap_6$, et d'indice au moins 6
(taille d'une orbite), donc c'est $\{\textnormal{id}\}$. $\varphi$ est ainsi
injective, et même bijective entre groupes de même cardinal.

Si $f$ était telle que $\varphi = \Sigmap(f)$, alors le stabilisateur de $H \in E$
pour l'action $\varphi$ serait le groupe des permutations ayant pour point fixe
$f^{-1}(H) \in \{1,\ldots,6\}$. Or ici, le stabilisateur de $H$ contient $H$, vu
comme sous-groupe de $\Sigmap_6$, qui agit transitivement donc dont les éléments
n'ont aucun point fixe commun. L'existence d'une telle $f$ est donc impossible.
$\varphi$ est donc un isomorphisme qui n'est pas induit par une bijection.

\newpage

\subsection{Non-isomorphisme exceptionnel (avec la réduction de Jordan)}

Dans H2G2 tome 1, ou encore dans le Perrin exercice IV.5.1. Le premier contient
des erreurs et le second est un exercice sans correction…

Posons $G = \PSL_4(\F_2)$ et $H = \PSL_3(\F_4)$. On va montrer que :
\begin{itemize}
\item $|G| = |H| = 20160$ ;
\item $G$ possède plusieurs classes de conjugaison d'éléments d'ordre 2 ;
\item $H$ n'en possède qu'une seule.
\end{itemize}
En conséquence de ces deux derniers points, $G \not\simeq H$. De plus, on sait
que :
\begin{theorem}
  $\PSL_n(\F_q)$ est simple sauf pour $n = 2$ et $q = 2,3$.
\end{theorem}
\begin{proof}
  C'est long…
\end{proof}
Une fois que nous aurons démontré les affirmations précédentes, ce dernier
théorème nous permettra de dire que $G$ et $H$ sont tous deux simples, de même
cardinal, et pourtant non isomorphes.

\paragraph{Comment compter les classes de conjugaison ?} Rappelons que sur tout
corps (pas forcément algébriquement clos), les matrices nilpotentes sont
classifiées à similitude près par la réduction de Jordan.

\begin{lemma}
  Les classes de similitudes de matrices nilpotentes d'indice 2 dans $\M_n(K)$
  sont en bijection avec $\{1, \ldots, \lfloor n/2 \rfloor\}$.
\end{lemma}
\begin{proof}
  Soit une telle classe, elle admet un unique représentant $N =
  \Diag(J_1, \ldots, J_k)$ où les $J_i$ sont des blocs de Jordan, de
  taille décroissante. $N^2 = 0$ signifie que $J_i^2 = 0$ pour tout $i$. Les
  blocs de Jordan sont donc de taille 1 ou 2. On réalise donc la bijection en
  comptant les blocs d'ordre 2 : il y en a forcément au moins un, sinon $N = 0$,
  et il peut y en avoir n'importe quel nombre jusqu'à $\lfloor n/2 \rfloor$ ($N$
  étant de taille $n$).
\end{proof}
\begin{corollary}
  Si $K$ est de caractéristique 2, il y a $\lfloor n/2 \rfloor$ classes de
  conjugaison d'ordre 2 dans $\GL_n(K)$.
\end{corollary}
\begin{proof}
  Soit $A \in \GL_n(K)$. $A$ est d'ordre deux ssi $A \neq I$ et $A^2 = I$, ce
  qui se réécrit aussi $A^2 - I = 0$ i.e. $(A-I)^2 = 0$ ($K[A]$ étant un anneau
  commutatif de caractéristique 2), i.e. $A-I$ nilpotente d'indice 2. Et $A$ est
  conjugué à $B$ (comme éléments du groupe) ssi $A-I$ est semblable à $B-I$
  (comme matrices). On est donc ramenés au lemme précédent.
\end{proof}
On a en fait classifié des orbites pour la conjugaison dans $\GL_n(K)$ en
prolongeant cette action de groupe à l'espace $\M_n(K)$…

\paragraph{Étude de $G$}

On a $G = \SL_4(\F_2)$ car $I$ est la seule homothétie, puis $G = \GL_4(\F_2)$
car $\det A \neq 0 \Leftrightarrow \det A = 1$ (tout ceci parce que $\F_2^* =
\{1\}$). Ainsi, 
\[ |G| = (2^4 - 1)(2^4 - 2)(2^4 - 2^2)(2^4 - 2^3) = 20160. \]
D'autre part, on peut directement appliquer le lemme précédent : il y a $\lfloor
4/2 \rfloor = 2$ classes de conjugaison d'ordre 2.

\paragraph{Étude de $H$}

On a tout d'abord $\GL_3(\F_4)/\SL_3(\F_4) \simeq \F_4^*$, puis $H \simeq
\SL_3(\F_4)/Z(\SL_3(\F_4))$ avec $Z(\SL_3(\F_4)) \simeq \F_4^*$. En effet,
toutes les homothéties sont dans $\SL_3(\F_4)$ : pour tout $\lambda \in \F_4^*$,
$\det \lambda I = \lambda^3 = 1$ car $\F_4^*$ est un groupe d'ordre 3. Le compte
donne
\[ |H| = \frac{(4^3 - 1)(4^3 - 4)(4^3 - 4^2)}{3^2} = 20160. \]

Dans $\GL_3(\F_4)$, il y a $\lfloor 3/2 \rfloor = 1$ classe de conjugaison
d'ordre 2. Si $A \in \SL_3(\F_4)$ est d'ordre 2, il est donc conjugué à la
transvection
\[ T = \left[\begin{matrix}
      1 & 1 & 0 \\
      0 & 1 & 0 \\
      0 & 0 & 1
    \end{matrix}\right] \]
ce qui s'écrit $A = PTP^{-1}$ avec $P \in \GL_3(\F_4)$. Peut-on choisir $P$ dans
$\SL_3(\F_4)$ ? Oui, quitte à la multiplier à droite par $\Diag(1,1,\det
P^{-1})$. Tout élément d'ordre 2 est donc conjugué à $T$ dans $\SL_3(\F_4)$.

Passons maintenant au quotient dans $H = \PSL_3(\F_4)$. Soit $A \in \SL_3(\F_4)$
tel que $\overline{A}^2 = \overline{I}$ dans $H$, c'est-à-dire $A^2 \in
Z(\SL_3(\F_4))$. Il existe donc $\lambda \in \F_4^*$ tel que $A^2 = \lambda I$.
Soit $\mu$ une racine carrée de $\lambda$ ; il en existe (exactement) une car $x
\mapsto x^2$ est un automorphisme (caractéristique 2 + finitude du corps). En
posant $B = \mu^{-1}A$, on a $\overline{A} = \overline{B}$ dans $H$, et $B^2 =
I$. $B$ est alors conjugué à $T$, et en projetant sur le quotient,
$\overline{A}$ est conjugué à $\overline{T}$ : la classe de conjugaison de ce
dernier est donc la seule, CQFD.

\newpage

\subsection{Théorème de l'élément primitif via le résultant}

(Cf. PDF de Paul Melotti.)

\begin{theorem}
  Si $L/K$ est une extension de corps finie séparable, alors il existe $\alpha
  \in L$ tel que $L = K(\alpha)$.
\end{theorem}

Comme on a \enquote{facilement} que $L = K(\alpha_1, \ldots, \alpha_n)$, on peut
faire une récurrence sur $n$ et il suffit pour cela de traiter le cas $n = 2$ :
$L = K(\alpha,\beta)$ avec $\alpha, \beta$ qui sont dans $L$ mais pas dans $K$.

Notons $P$ et $Q$ sont les polynômes minimaux respectifs de $\alpha$ et $\beta$
sur $K$. On cherche $\gamma$ tel que $L = K(\gamma)$, qu'on cherche de la forme
$\gamma = \alpha + t\beta$.

\newpage

\subsection{Enveloppe convexe du groupe orthogonal}

Je propose ici une démonstration bien plus expéditive que celle qu'on trouve
par-ci par-là dans des PDF sur Internet, relativement autosuffisante avec le
programme de math spé (pas besoin de théorèmes un peu compliqués à démontrer
comme Hahn-Banach géométrique, donc). Mais du coup c'est peut-être un peu court…

On considère $\R^n$ muni de sa norme euclidienne canonique $\|\cdot\|$, $O(n)$
le groupe orthogonal.

Le seul prérequis sera le suivant :

\begin{theorem}[Décomposition en valeurs singulières]
  Soit $M \in \M_n(\R)$, alors il existe $U, V \in O(n)$ et $D$ diagonale à
  coefficients positifs tels que $M = UDV$.
\end{theorem}
\begin{proof}
  On s'est placé dans le cas particulier des matrices carrées, donc il suffit
  d'enchaîner décomposition polaire et théorème spectral.
\end{proof}

Énonçons également un petit lemme qu'il sera bon d'illustrer avec un
\textbf{dessin} dans $\R^2$ :
\begin{lemma}
  $\mathrm{Conv}(\{-1,1\}^n) = [-1,1]^n$.
\end{lemma}
\begin{proof}
  On aimerait parachuter une formule explicite, mais c'est sans doute pénible,
  vu que ça devra impérativement faire intervenir tous les $2^n$ sommets de
  l'hypercube… Sinon, il est clair que $\mathrm{Conv}({-1,1}) = [-1,1]$, d'où
  l'on déduit que
  \[ \bigcup_{x \in [-1,1]}
  \mathrm{Conv}(\{x\} \times \{-1,1\}^{n-1}) \subseteq
  \mathrm{Conv}(\{-1,1\}^n) \]
  puis on conclut par récurrence.
\end{proof}


Maintenant, soit $||| \cdot |||$ la norme subordonnée sur $\M_n(\R)$ et $B$ la
boule unité \emph{fermée} de $\M_n(\R)$ pour cette norme.

\begin{theorem}
  $B$ est l'enveloppe convexe de $O(n)$. 
\end{theorem}

\begin{proof}
  Tout d'abord, il est clair que les matrices orthogonales, étant des
  isométries, sont de norme 1, donc $O(n) \subset B$. $B$ étant convexe, il
  contient également l'enveloppe convexe de $O(n)$.

  Soit $M \in B$. Écrivons sa SVD : $M = UDV$ où $U, V \in O(n)$ et $D =
  \Diag(d_1, \ldots, d_n)$. Comme $|||D||| \leq 1$, on a $|d_i| \leq 1$ pour
  tout $i$. Le lemme précédent nous permet donc d'écrire $D$ comme barycentre de
  la forme $\Diag(\pm 1, \ldots, \pm 1)$. Ces matrices sont des symétries
  orthogonales, elles sont dans $O(n)$. En multipliant par $U$ à gauche et $V$ à
  droite, on a $M \in \mathrm{Conv}(O(n))$.
\end{proof}

\begin{theorem}
  $O(n)$ est l'ensemble des \emph{points extrêmes} de $B$, c'est-à-dire des
  points qui ne peuvent pas s'écrire comme barycentres d'autres points de $B$.
\end{theorem}

\begin{proof}
Soit $U \in O(n)$, montrons que c'est un point extrême de $B$.

Posons $\varphi : M \mapsto \Tr(U^{-1}M)$, $\varphi \in \M_n(\R)^*$. Pour
tout $M \in B$, on a (puisque $\| U^{-1}M e_i \| \leq 1$)
\[ \varphi(M) = \Tr(U^{-1}M) = \sum_{i=1}^n \langle U^{-1}M e_i \mid e_i \rangle
  \leq \sum_{i=1}^n \| U^{-1}M e_i \| \cdot \| e_i \| \leq n \]

et on a égalité dans Cauchy-Schwarz si et seulement si,
pour tout $i$, (i) $\| U^{-1}M e_i \| = 1$ et (ii) $U^{-1}M e_i$ et $e_i$ sont
positivement liés, soit $U^{-1}M e_i = e_i$ pour tout $i$, ce qui est équivalent
à $U^{-1}M = I$ ou encore à $M = U$.

Ainsi, d'une part $\varphi(U) = n$, d'autre part, pour tout barycentre $G =
\sum_{i=1}^k \alpha_i M_i$ avec $M_i \in B \setminus \{U\}$, on a $\varphi(M_i) <
n$ pour tout $i$ donc $\varphi(G) < n$. Forcément $U \neq G$ : $U$ est un point
extrême.
\end{proof}

Conséquence de la preuve : pour chaque point extrême, il existe un hyperplan
d'appui intersectant $B$ uniquement en ce point.

% \paragraph{Enveloppe convexe de $O(n)$} Nous voulons montrer que
% $\mathrm{Conv}(O(n)) = B$, sachant qu'une inclusion a déjà été montrée.
% À ce stade, nous pourrions conclure directement en invoquant le théorème de
% Krein-Milman, mais il est difficile à démontrer. Procédons autrement, avec les
% résultats suivants :

% \begin{theorem}[Carathéodory]
%   Soit $X$ une partie d'un espace affine de dimension $n$. tout point
%   $\mathrm{Conv}(X)$ s'écrit comme barycentre d'au plus $n+1$ points de $X$.
% \end{theorem}
% \begin{corollary}
%   Si $K$ est une partie compacte d'un espace affine de dimension finie,
%   $\mathrm{Conv}(K)$ est compacte.
% \end{corollary}

% Ce qui nous permet d'affirmer que $\mathrm{Conv}(O(n))$ est compact (comme quoi,
% ce n'est pas si trivial que ça).

% \begin{theorem}
%   Dans un espace affine de dimension finie, si $K$ est convexe fermé et $x
%   \not\in K$, alors il existe un hyperplan séparant strictement $x$ et $K$.
% \end{theorem}
% \begin{proof}
%   On peut appliquer directement le théorème de Hahn-Banach géométrique ($\{x\}$
%   étant convexe compact), ou bien utiliser la projection sur un convexe fermé
%   dans un espace de Hilbert.
% \end{proof}

% Supposons par l'absurde qu'il existe $M \in B \setminus \mathrm{Conv}(O(n))$.
% Alors il existe un hyperplan séparateur, fourni par une forme linéaire $\phi$
% telle que pour tout $U \in \mathrm{Conv}(O(n))$, $\phi(U) < \phi(M)$. Comme
% $\Tr(- \times -)$ est une forme bilinéaire non dégénérée, en fait,
% \[ \exists A \in \M_n(\R) \,/\, \forall U \in O(n),\, \Tr(AU) < Tr(AM) \]


\newpage

\subsection{Théorème de Lie-Kolchin}

Un long exercice dans H2G2 tome 1, corrigé dans la nouvelle édition (p. 238).

\begin{definition}
  Le \emph{groupe dérivé} $D(G)$ d'un groupe $G$ est le sous-groupe engendré par
  les commutateurs $[g,h]= ghg^{-1}h^{-1}$. $G$ est dit \emph{résoluble} s'il
  existe $l$ tel que $D^l(G) = \{1\}$.
\end{definition}
\begin{proposition}
  Pour tout $k \in \N$, $D^k(G) \trianglelefteq G$.
\end{proposition}
\begin{proof}
  On montre par récurrence que $D^k(G)$ est stable par tout $\varphi \in
  \Aut(G)$. Le cas de base $k=0$ est immédiat. Supposons que $\varphi(D^k(G)) =
  D^k(G)$ ; alors $\varphi$ se restreint en un automorphisme de $D^k(G)$ et la
  formule $\varphi([g,h]) = [\varphi(g),\varphi(h)]$ ($g,h \in D^k(G)$) montre
  qu'il stabilise $D^{k+1}(G)$.

  Il suffit pour conclure d'appliquer ceci à un automorphisme intérieur de $G$
  (mais attention, l'automorphisme restreint sur $D^k(G)$ n'est pas forcément
  intérieur, d'où la nécessité d'une hypothèse de récurrence plus forte que
  $D^k(G) \trianglelefteq G$).
\end{proof}

\begin{proposition}
  Le groupe dérivé d'un groupe connexe est connexe.
\end{proposition}
\begin{proof}
  Admis.
\end{proof}

L'objectif est de montrer :

\begin{theorem}[Lie--Kolchin]
  Soit $G$ un sous-groupe résoluble connexe de $\GL_n(\C)$. Les matrices de $G$
  sont cotrigonalisables. De façon équivalente, $G$ est conjugué à un
  sous-groupe des matrices triangulaires inversibles.
\end{theorem}

Si $G$ est abélien, la conclusion est bien connue. Sinon, $n \geq 2$ et il
suffit de montrer que $G$ admet un sous-espace stable non triviale : ainsi, on
pourra trigonaliser par blocs et conclure par récurrence forte sur $n$.
Attention, la récurrence nécessite d'utiliser le fait que l'extraction d'un bloc
diagonal est un morphisme de groupes continu, et d'utiliser la propriété
suivante (admise) :
\begin{proposition}
  L'image par un morphisme d'un groupe résoluble est résoluble.
\end{proposition}

Supposons donc $G$ non abélien. Soit $l$ minimal tel que $D^l(G) = \{1\}$, alors
$l \geq 2$ et $H = D^{l-1}(G)$ est abélien.

$H$ est donc cotrigonalisable, et admet donc un vecteur propre commun $v$. On
pose $V = \Vect(Gv)$ où $Gv = \{Mv \mid M \in G\}$. C'est bien un sous-espace
stable par $G$, et non réduit à $\{0\}$ ; reste à montrer que $V \neq \C^n$.

Montrons que $H$ agit par homothéties sur $V$. Fixons $A \in H$. Pour tout $P
\in G$, $P^{-1}AP \in A$ ($A = D^{l-1}(G) \triangleleft G$) ; $v$ étant vecteur
propre commun $P^{-1}APv = \lambda_P v$ pour un certain $\lambda_P \in \C$, ce
qui s'écrit aussi $APv = \lambda_P Pv$.

Maintenant, $\lambda_P$ est une fonction continue de $P$ : en effet, elle
s'écrit $\langle APv, Pv \rangle / \|Pv\|^2$ en utilisant le produit hermitien
canonique. L'ensemble $\{ \lambda_P \mid P \in G \}$ est donc connexe puisque
$G$ l'est. Or les $\lambda_P$ sont inclus dans le spectre de $A$, invariant par
conjugaison, et discret. Donc $\lambda_P$ est constant. $A$ est donc une
homothétie sur $Gv$, puis sur $V$.

Si maintenant $V = \C^n$, alors $A \subseteq \C^*I$. Comme $A$ est un groupe
dérivé (car $G$ non abélien !) et $\det\,[g,h] = 1$, $\det = 1$ sur $A$. D'où $A
\subset \mathbb{U}_nI$, or $A$ est connexe, donc $A$ est le groupe trivial.
Contradiction. Ainsi, $\{0\} \subsetneq V \subsetneq \C^n$, et on peut enchaîner
sur la récurrence.

Dans cette dernière étape, on a eu recours à la propriété suivante :
\begin{proposition}
  L'image par un morphisme d'un groupe résoluble est résoluble.
\end{proposition}

\newpage


\subsection{Constructibilité des polygones réguliers}

\[ \Q(\zeta_p) = K_m \supset K_{m-1} \supset \ldots \supset K_0 = \Q \]
\[ \{0\} \hookrightarrow \Z/2\Z \hookrightarrow \ldots \hookrightarrow \Z/2^n\Z
  \simeq (\Z/pZ)^* \simeq \textnormal{Gal}(\Q(\zeta_p)/\Q) \]

TODO. Utiliser un élément primitif pour borner le nombre d'automorphismes fixant
une extension intermédiaire d'un corps cyclotomique, ce qui évite d'avoir à
prouver un sens du lemme d'Artin.


\subsection{Quatre autres développements}

\begin{itemize}
\item Réciprocité quadratique par double comptage d'une conique sur $\F_p$ (trop
  beau !) : dans H2G2 tome 1
\item Sous-groupe de Frattini et théorème de la base de Burnside : problème 3
  dans Zavidovique
\item Algorithme de Berlekamp : cf. PDF de Jill-Jênn Vie
\item Existence de la réduction de Frobenius (utilisant l'orthogonalité duale) :
  fait en cours dans H2G2 tome 1
\end{itemize}


\newpage

\section{Analyse}

\subsection{Les fonctions monotones (continues) sont dérivables presque partout}

Un joli résultat suggéré par le rapport de jury d'agrég… mais c'est long !
(Peut-être trop pour 15 minutes ?) Ce qui suit est une tentative de
démonstration qui s'inspire princpalement des \emph{Leçons d'analyse
  fonctionnelle} de Riesz \& Szokefalvi-Nagy, la fin étant tirée de \emph{Real
  Analysis}, Royden (ou Royden \& Fitzpatrick pour la dernière édition). À la
fin de la section, on trouvera des compléments culturels.

On va se restreindre ici aux fonctions monotones \emph{continues}. Même avec
cette hypothèse, ça reste technique, attention !
\begin{theorem}
  Soit $f : [0,1] \to \R$ une fonction continue croissante. Alors $f$ est
  dérivable presque partout.
\end{theorem}

\begin{definition}
  On notera $\displaystyle \Delta f(x,y) = \frac{f(y) - f(x)}{y - x}$ pour $x
  \neq y$ et $f : \R \to \R$.
\end{definition}
Notation dont l'utilité ne fait aucun doute s'agissant de parler de dérivation
d'une fonction d'une variable réelle.

\paragraph{Résultats préliminaires} Commençons par deux petites propositions.
Pour $U \subseteq \R$ un ouvert, notons $CC(U)$ l'ensemble de ses composantes
connexes.
\begin{proposition}
  Les composantes connexes de $U$ sont des intervalles ouverts disjoints,
  en nombre au plus dénombrable, dont la réunion est égale à $U$.
\end{proposition}
\begin{proof}
  Admis, mais c'est classique et facile, donc à savoir démontrer sans hésiter.
\end{proof}
\begin{proposition}
  Soit $f : [a,b] \to \R$ croissante et $U \subset [a,b]$ ouvert dans $\R$.
  Alors
  \[ \sum_{]c,d[ \in CC(U)} (f(d)-f(c)) \leq f(b) - f(a) \]
  les termes de la somme étant positifs.
  Autrement dit, la \textnormal{variation totale} de $f$ sur $[a,b]$ est
  $f(b) - f(a)$.
\end{proposition}
\begin{proof}
  
  Supposons dans un premier temps $|CC(U)| < \infty$, soit $CC(U) =
  \{]c_1,d_1[,\ldots,]c_n,d_n[\}$ avec $c_1 < d_1 \leq c_2 < \ldots \leq d_n$.
  Alors pour tout $i$, $f(d_i) \leq f(c_{i+1})$ car $f$ croissante, donc
  \[ \sum_{i=1}^n (f(d_i) - f(c_i)) = - f(c_1) + (f(d_1) - f(c_2)) + \ldots +
    (f(d_{n-1}) - f(c_n)) + f(d_n) \leq f(d_n) - f(c_1) \]
  Dans le cas $CC(U)$ dénombrable, il suffit de passer à la limite sur les
  sous-familles finies.
\end{proof}

Le lemme qui suit est fondamental dans la preuve du théorème.

\begin{lemma}[des rayons du soleil]
  Soit $f : [a,b] \to \R$ continue et soit $\alpha \in \R$. Posons
  \[ O_g(]a,b[,\alpha)  = \left\{ x \in ]a,b[ | \exists y \in ]a,x[\,/\,
      \Delta f(x,y) < \alpha \right\} \]
  \[ O_d(]a,b[,\alpha) = \left\{ x \in ]a,b[ | \exists y \in ]x,b[\,/\,
      \Delta f(x,y) > \alpha \right\}
  \]
  Alors $O_g(]a,b[,\alpha)$ et $O_d(]a,b[,\alpha)$ sont ouverts dans $\R$ et
  \begin{enumerate}
  \item Pour tout $]c,d[ \in CC(O_g(]a,b[,\alpha))$,
    $\displaystyle \Delta f(c,d) \leq \alpha$.
  \item Pour tout $]c',d'[ \in CC(O_d(]a,b[,\alpha))$,
    $\displaystyle \Delta f(c',d') \geq \alpha$.
  \end{enumerate}
\end{lemma}
Il faut \textit{\textbf{faire un dessin}} pour voir ce qui se passe :
l'hypographe de $f$ est éclairé par un faisceau de rayons parallèles de pente
$\alpha$ provenant de la gauche dans le cas 1, la droite dans le cas 2, et les
ensembles définis sont les zones à l'ombre (la lumière passant à travers les
points de tangence). On peut constater visuellement qu'il y a en fait égalité
sauf éventuellement pour $d = b$ ou $c' = a$, mais nous n'aurons pas besoin de
le prouver formellement.

Remarquons que (1) découle de (2) appliqué à $x \mapsto -f(-x)$, et qu'on peut
se ramener à $\alpha = 0$ quitte à soustraire une fonction linéaire. (Et en
considérant $-f$, on peut obtenir deux autres cas, consistant à éclairer
l'épigraphe au lieu de l'hypographe.) Ce dernier cas est celui généralement
énoncé dans la littérature sous le nom de \enquote{rising sun lemma} (en effet,
$\alpha = 0$ revient à placer le soleil à l'horizon(tale), et les rayons
viennent de la droite i.e. de l'est).

\begin{proof}[Démonstration du \enquote{rising sun lemma}]
  $U$ est ouvert car les inégalités strictes de fonctions continues définissent
  des ouverts, et une projection linéaire d'un ouvert sur une coordonnée
  est un ouvert\footnote{Banach--Schauder en dimension finie !}.

  Soit $]c,d[ \in CC(U)$, on veut maintenant montrer que $f(d) - f(c) \geq 0$.
  Fixons $\varepsilon > 0$. Par compacité, $f$ atteint son maximum sur
  $[c+\varepsilon, d]$ en un point $x$. En particulier $f(x) \geq f(d)$. Or
  $f(d) \geq f(z)$ pour tout $z > d$ car $d \not\in U$. Ainsi $f(x) \geq f(y)$
  pour tout $y > x$, bref, aucun point ne peut faire de l'ombre à $x$ : $x
  \not\in U$. Or $[c+\varepsilon,d[ \subset U$, donc $x = d$. Autrement dit le
  maximum est atteint en l'unique point $d$, d'où $f(c+\varepsilon) < f(d)$, et
  en passant à la limite $f(c) \leq f(d)$.
\end{proof}

Ceci étant établi, c'est parti pour commencer à parler du théorème principal.

\paragraph{Stratégie d'attaque du théorème}
Soit $f : [0,1] \to \R$ continue croissante.
Définissons ses \emph{dérivées de Dini}
\[ D^+f(x) = \limsup_{y \to x^+} \Delta f(x,y) \qquad
  D^-f(x) = \limsup_{y \to x^-} \Delta f(x,y) \]
\[  D_+f(x) = \liminf_{y \to x^+} \Delta f(x,y) \qquad
  D_-f(x) = \liminf_{y \to x^-} \Delta f(x,y) \]

$f$ est dérivable en un point $x$ si et seulement si ces quatre limites (1)
coïncident et (2) sont finies. Nous allons établir que c'est le cas presque
partout. Mais d'abord, faisons le lien avec tout ce dont nous avons parlé avant.

\begin{remark}
  Soient $a < b$, $x \in ]a,b[$ et $\alpha < D_+f(x)$. Alors $x \in O_d(]a,b[,
  \alpha)$. De même, si $\alpha > D_-f(x)$, alors $x \in O_g(]a,b[, \alpha)$.
\end{remark}
\begin{proof}
  $\limsup_{y \to y^+} \Delta f(x,y) > \alpha$ et $]x,b[$ est un voisinage à
  droite de $x$ donc il existe $y \in ]x,b[$ tel que $\Delta(x,y) > \alpha$ :
  c'est exactement la condition d'appartenance à $O_d(]a,b[,\alpha)$.
\end{proof}

On dispose enfin de tous les outils pour attaquer le cœur de la preuve !

\begin{proof}[(1) Existence p.p. de la limite]
Montrons dans un premier temps que $D^+f \leq D_-f$ presque partout. Pour cela,
fixons $\alpha < \beta$ quelconques et posons
\[ S_{\alpha,\beta} = \{ x \in ]0,1[ \mid D_-f(x) < \alpha < \beta < D^+f \} \]
On veut montrer que $S_{\alpha,\beta}$ est de mesure nulle.

En partant de $E_0 = ]0,1[$, nous allons définir par récurrence deux suites de
parties de $\R$ : pour $n \in \N$,
\[ F_n = \bigcup_{I \in CC(E_n)} O_g(I, \alpha) \qquad
   E_{n+1} = \bigcup_{I \in CC(F_n)} O_d(I, \beta) \]
On a $E_0 \supset F_0 \supset E_1 \ldots$ et le lemme des rayons du soleil (à
l'aide une récurrence triviale) garantit que ce sont des ouverts. 

Si $x \in S_{\alpha,\beta}$, la remarque établie plus haut nous dit que comme
$D_-f(x) < \alpha$, $x \in F_0$, puis comme $D^+f(x) > \beta$, $x \in E_1$, et
ainsi de suite… Au bout du compte, $S_{\alpha,\beta} \subset \bigcap_{n \in \N}
E_n$ et nous allons montrer que ce dernier ensemble est négligeable.

Soit $n \in \N$. Soit $]a,b[ \in CC(F_n)$, le cas 1 du lemme nous dit que
$f(b) - f(a) \leq \alpha(b-a)$. Si maintenant $]c,d[ \in CC(E_{n+1} \cap
]a,b[)$, alors le cas 2 du lemme donne $f(d)-f(c) \geq \beta(d-c)$. En sommant
et en appliquant notre majoration de la variation totale, on a :
\[ \beta\mu(E_{n+1} \cap ]a,b[) = \sum_{]c,d[} \beta\mu(]c,d[) \leq \sum_{]c,d[}
  (f(d) - f(c)) \leq f(b) - f(a) \leq \alpha\mu(]a,b[) \]
\[ \mu(E_{n+1}) \leq \frac{\alpha}{\beta} \sum_{]a,b[} \mu(]a,b[) =
  \frac{\alpha}{\beta} \mu(F_n) \leq \frac{\alpha}{\beta} \mu(E_n) \] où $\mu$
est la mesure de Lebesgue. Comme $\alpha/\beta < 1$ et $E_0 = [0,1]$ est de
mesure finie,
\[ \mu(S_{\alpha,\beta}) \leq \mu \left( \bigcap_{n=0}^\infty E_n \right)
  \leq \lim_{n \to \infty} \left( \frac{\alpha}{\beta} \right)^n \mu(E_0) = 0 \]
\[ \mu\left( \{x \in ]0,1[ \mid  D^+f(x) > D_-f(x) \} \right)
  = \mu\left( \bigcup_{\alpha, \beta \in \Q} S_{\alpha,\beta} \right)
  = 0 \]
De façon analogue on peut montrer que $D^-f \leq D_+f$ p.p., ce qui suffit à
obtenir l'égalité p.p. des quatre dérivées de Dini : en effet, on sait que
$\liminf \leq \limsup$ donc $D_+f \leq D^+f$ et $D_-f \leq D^-f$.
\end{proof}

Notons $f'(x)$ cette limite commune qui existe pour tout $x$ hors d'un ensemble
de mesure nulle : on définit ainsi une fonction $f'$, qu'on étend arbitrairement
à $\R$. $f'$ est à valeurs dans $\R_+ \cup \{+\infty\}$. En effet, $f$ étant
croissante, ses taux d'accroissements sont positifs ; et rien ne garantit a
priori que la limite de ces taux d'accroissements soit finie. Reste à montrer :

\begin{proof}[(2) Finitude p.p. de la dérivée]
Calculons d'abord, en prolongeant $f$ par $f(1)$ sur $]1,+\infty[$,
\[
  \int_0^1 \frac{f(x+h) - f(x)}{h}dx =
    \frac{1}{h} \int_1^{1+h} f(x)\,dx - \frac{1}{h} \int_0^h f(x)\,dx
    \underset{h \to 0^+}{\longrightarrow} f(1) - f(0)
\]
où la dernière égalité est vraie par continuité de $f$. Comme $f'$ est mesurable
(en tant que limite de fonctions mesurables) et positive, on peut l'intégrer et
le lemme de Fatou nous donne
\[ \int_0^{1} f'(x)\,dx \leq \lim_{h \to 0^+}
  \int_0^{1} \frac{f(x+h) - f(x)}{h}dx =
  f(1)- f(0) < +\infty \]
Ainsi, $f'$ est positive et intégrale, elle est donc finie presque partout.
\end{proof}

\paragraph{Conclusion} En excluant d'abord les points où le taux d'accroissement
n'a pas de limite, puis ceux où la limite est $+\infty$, on ne s'est privé que
d'en semble de mesure nulle, donc : $f$ est dérivable presque partout !

Le théorème se généralise évidemment à un intervalle de définition quelconques
(par union dénombrable de segments compacts), et il est tout aussi clair que
l'énoncé s'applique aussi pour $f$ décroissante. Par contre, attention, il n'est
pas facile de généraliser à $f$ discontinue !

\paragraph{À propos de l'hypothèse de continuité} Cette hypothèse était présente
dans la première démonstration de ce théorème par Lebesgue en 1904.

Quand $f$ est discontinue, on pourrait vouloir se restreindre à ses intervalles
de continuité pour se ramener au cas qu'on a prouvé. Un contre-exemple à cette
stratégie naïve est donné par la fonction $f : x \mapsto \sum_{n \in \N} 2^{-n}
\Indic_{[x \geq q_n]}$ où $(q_n)_{n \in \N}$ est une énumération des rationnels.
Il faut donc traiter le cas de ce genre de \emph{fonctions de saut} (et en fait,
toute fonction monotone est la somme d'une fonction continue et d'une fonction
de saut, puisqu'une fonction monotone a un nombre au plus dénombrable de points
de discontinuité).

On trouvera chez Royden une preuve directe du cas général ($f$ potentiellement
discontinue) utilisant le lemme de recouvrement de Vitali. Dans ce livre, ce
théorème est le premier d'une séquence qui aboutit à montrer que pour les
fonctions d'une variable réelle la dérivation est bien l'opération inverse de
l'intégrale de Lebesgue (presque partout, évidemment).

\paragraph{Dernière remarque culturelle}

En utilisant la majoration de la variation totale et le lemme des rayons du
soleil, on peut aussi démontrer (et ça a quasiment déjà été fait !) que
\[ \mu\left( \left\{ x \in ]0,1[ \mid D^+f(x) \geq \beta \right\} \right)
  \leq \frac{f(1)-f(0)}{\beta} \]
ce qui aurait pu permettre de traiter la partie finitude (exercice pour la
lectrice). Ce résultat est à comparer avec le suivant, utilisé pour démontrer
d'autres théorèmes de dérivation presque partout dans le même esprit (cf. par
exemple \emph{An introduction to measure theory} de Terence Tao) :
\begin{theorem}[Inégalité maximale de Hardy-Littlewood]
  Soit $f \in L^1(\R)$, et soit $\beta > 0$. Alors
  \[ \mu\left( \left\{ x \in \R \;\middle|\; \sup_{h > 0} \frac{1}{h} \int_x^{x+h}
        |f(t)|\,dt \geq \beta \right\} \right)
    \leq \frac{1}{\beta} \int_\R |f(t)|\,dt \]
\end{theorem}

À ce propos, le lecteur est invité à se pencher sur l'énoncé d'un exercice qui
m'a été posé au concours d'entrée des ENS, en 2012 :
\begin{enumerate}
\item Montrer que tout ouvert de $\mathbb{R}$ est une réunion disjointe dénombrable d'intervalles ouverts.
\item On prend une fonction continue sur un intervalle de $\mathbb{R}$ et on desssine son graphe. On fait arriver de la droite ($x = +\infty$) un faisceau lumineux de rayons parallèles à l'axe des abscisses. Ce faisceau éclaire certaines parties du graphe, le reste étant dans l'ombre (on considérera qu'un rayon arrivant tangent en un extrémum n'est pas bloqué). Montrer que l'ensemble des abscisses des points à l'ombre est une union disjointe d'intervalles ouverts.
\item Soit $(u_n)_{n \in \mathbb{Z}} \in \mathbb{R}^{\mathbb{Z}}$ une suite \emph{sommable}. On pose $u^*_N = \displaystyle \sup_{n \in \mathbb{N}^*} \frac{1}{n} \sum_{k=0}^{n-1} u_{N+k}$.\\ Montrer que $\displaystyle \sum_{\underset{u_N^* > 0}{N \in \mathbb{Z}}} u_N \geq 0$.
\end{enumerate}
L'examinateur affirmait que les question (2) et (3) étaient liées. Quatre ans se
sont écoulés avant que je ne comprenne ce lien, en travaillant le développement
ci-dessus… On admirera au passage les contorsions nécessaires pour contourner
l'absence de l'intégrale de Lebesgue au programme des classes préparatoires.
\begin{proof}[Solution de la question 3, datant de l'époque]
  Pour simplifier l'écriture on va poser
  \[E = \left\{ N \in \mathbb{Z} \mid u^*_N > 0 \right\}\]
  Soit $N \in E$. $u_N$ n'est pas forcément positif (sinon, ça serait trop
  simple). Par contre,
  \[ u^*_N > 0 \quad \Leftrightarrow \quad
    \exists n \in \mathbb{N}^* \,/\, \sum_{k=0}^{n-1} u_{N+k} > 0 \]
  Si $u_N < 0$, alors $ \sum_{k=0}^{n-2} u_{N+1+k} \geq
  \sum_{k=0}^{n-1} u_{N+k} > 0$ donc $u_{N+1} \in E$.
  On peut espérer que pour un bon choix de $n$, $\{N,N+1,\ldots,N+n-1\} \subset E$
  ce qui permettrait de découper la somme en morceaux positifs.

Prenons donc $n$ minimal vérifiant $ \sum_{k=0}^{n-1} u_{N+k} > 0$. Si $u_{N+p}
\not\in E$ pour $0 < p < n$, alors $ \sum_{k=p}^{n-1} u_{N+k} \leq 0$ donc $
\sum_{k=0}^{p-1} u_{N+k} > 0$ ce qui contredit la minimalité de $n$. Ainsi, on a
bien l'inclusion souhaitée.

À partir de ce lemme, on montre que
 \[ \sum_{\underset{N \geq N_0}{N \in E}} u_N > 0 \]
 pour tout $N_0$ en construisant une sous-suite positive et croissante de la
suite des sommes partielles. On conclut en faisant $N_0 \to -\infty$.

\end{proof}

\newpage

\subsection{Récurrence d'une marche aléatoire via séries de Fourier}

Un théorème célèbre, avec une preuve étrangement moins célèbre et pourtant
stylée, que j'ai découverte dans le cours de processus aléatoires de Josselin
Garnier et qui est également trouvable sur Internet.

\begin{theorem}[Pólya]
  La marche aléatoire symétrique sur $\Z^d$ est \emph{récurrente} si et
  seulement si $d \leq 2$.
\end{theorem}

Précisons ce que signifie \enquote{récurrente}. Cette marche aléatoire est
définie par la suite de v.a. $S_n = X_1 + \ldots + X_n$ où les $(X_i)$ sont iid
uniformes parmi $\{\pm e_1, \ldots, \pm e_d\}$. Soit $N$ le nombre de passages à
l'origine : $N = \mathrm{Card}\left\{n \in \N \mid S_n = 0\right\}$. On dit que
la marche est récurrente quand $\E[N] = +\infty$.


\paragraph{Premières remarques} On a $\displaystyle \E[N] = \E\left[
  \sum_{n=0}^\infty \Indic_{\{S_n = 0\}} \right] =
\sum_{n=0}^\infty \P(S_n = 0)$.\\
On peut ne garder que les termes pairs dans cette somme. En effet, pour tout $n
\in \N$, on établit facilement que $\sum_{i=1}^d \langle S_n, e_i \rangle \equiv
n \mod 2$, ce qui entraîne que $S_n \neq 0$ quand $n$ est impair.\\
On cherche donc une expression pour $\P(S_n = 0)$, $n = 2m$ avec $m \in \N$.

\paragraph{Utilisation de la fonction caractéristique}

Si $\varphi$ est la fonction caractéristique de $X_1$, alors celle de $S_n$
est égale à $\varphi^n$ (somme de v.a. indépendantes).

\[ \forall x \in \R^d,\quad \varphi(x) = \E\left[ e^{i \langle x, X_1 \rangle}
  \right]
  = \sum_{j=1}^d \left( \frac{1}{2d}e^{ix_j} + \frac{1}{2d}e^{-ix_j}\right)
  = \frac{1}{d} \sum_{j=1}^d \cos(x_i) \]

Pour en déduire les probabilités recherchées on utilise :
\begin{lemma} Soit $k = (k_1, \ldots, k_d) \in \Z^d$. On a la formule des
  coefficients de Fourier :
 \[ \displaystyle \P(S_n = k) = \frac{1}{(2\pi)^d} \int_{[-\pi,\pi]^d} \varphi_n(x)e^{-i\langle k,x \rangle} \]
\end{lemma}
En fait, $\varphi_n$ est une série de Fourier $d$-dimensionnelle normalement
convergente dont les coefficients sont les $\P(S_n = (k_1, \ldots, k_d))$. Ce
n'est pas anecdotique : la preuve qu'on est en train de dérouler repose
fondamentalement sur un passage au domaine de Fourier\footnote{Ici les
  \enquote{fréquences} (le dual) sont dans le tore et le \enquote{temps} (le
  primal) est discret ; on est habitués à l'autre sens, mais c'est juste
  l'involutivité de la dualité de Pontriaguine. Les anglophones parlent de
  \enquote{discrete-time Fourier transform}, à ne pas confondre avec la
  transformée de Fourier discrète d'un signal \emph{fini}.} pour convertir une
convolution de mesures en produit de fonctions, c'est complètement dans l'esprit
de l'analyse de Fourier. Mais ici, pas besoin de toute cette théorie, il suffit
de calculer :
\begin{proof}[Preuve du lemme]
  \[ \int_{[-\pi,\pi]^d} \varphi_n(x)e^{-i\langle k,x \rangle} dx =
    \int_{[-\pi,\pi]^d} \E\left[ e^{i\langle S_n, x \rangle} e^{-i\langle k,x
        \rangle}\right] dx
    = \E\left[ \int_{[-\pi,\pi]^d} e^{i\langle S_n - k, x \rangle} dx \right]
    = \E\left[ (2\pi)^d \Indic_{\{S_n = k\}} \right] \]
  où on a pu intervenir $\int$ et $\E$ grâce au théorème de Fubini appliqué à
  une fonction bornée, donc intégrable sur un produit d'espaces de mesure finie.
\end{proof}
Ainsi, en se souvenant que $\varphi$ est à valeurs réelles, ses puissances
paires sont positives (!), et
\[ (2\pi)^d \E[N] = \sum_{m=0}^{\infty} \int_{[-\pi,\pi]^d} \varphi(x)^{2m} dx
  = \int_{[-\pi,\pi]^d} \frac{dx}{1 - \varphi(x)^2}\]
par convergence monotone, l'expression finale étant valable parce que
$|\varphi(x)| < 1$ presque partout. (Si on avait gardé les termes impairs (qui
peuvent être négatifs), comme c'est le cas dans certaines références,
l'interversion série-intégrale aurait été plus dure à justifier ; il faut une
astuce dans ce cas…)

\paragraph{Étude d'une intégrale et conclusion} Il s'agit donc de savoir si
cette intégrale est finie ou non. $1/(1-\varphi^2)$ part à l'infini exactement
aux points où il y a un problème de convergence à savoir $|\varphi| = 1$ , soit
$(0,\ldots,0)$ ainsi que les $2^d$ points $(\pm \pi, \ldots, \pm \pi)$ ; et elle
est continue en-dehors de ces points. Ces derniers points sont des anti-périodes
de $\varphi$, donc des périodes de $1/(1-\varphi^2)$ : il suffit donc d'étudier
l'intégrabilité en 0, sur un voisinage $B(0,\varepsilon)$ où $0 < \varepsilon <
\pi$.

Pour $x \to 0$,
\[ 1 - \varphi(x) = \frac{1}{d} \sum_{j=1}^d (1 - \cos x_j) \sim
  -\frac{1}{d}(x_1^2 + \ldots + x_d^2) \] d'où
\[\frac{1}{1 - \varphi(x)^2} = \frac{1}{(1 + \varphi(x))(1 - \varphi(x))} \sim
  \frac{2d}{\|x\|^2} \]
Finalement, reste à étudier l'intégrabilité de $\|x\|^{-2}$. Un passage en
coordonnées polaires et le théorème de Tonelli donnent
\[ \int_{B(0,\varepsilon)} \|x\|^{-2}\,dx = \int_{]0,\varepsilon[ \times S^{d-1}}
  r^{-2} \cdot r^{d-1}\,dr\,d\omega = \Vol(S^{d-1}) \int_0^\varepsilon
  r^{d-3}\,dr \]
Ce qui est infini exactement quand $d < 3$, CQFD.

Petit détail : le cas $d=1$ semble nécessiter un traitement particulier,
mais le calcul est bien légal à condition de considérer que $S^0 = \{\pm 1\}$
(c'est bien la convention habituelle) et de prendre pour mesure 0-dimensionnelle
la mesure de comptage. Les \enquote{coordonnées polaires} correspondent alors à
la décomposition en signe et valeur absolue, qui est bien un
$\Cf^1$-difféomorphisme entre $\R^*$ et $S^0 \times \R_+^*$ !

\paragraph{Si le temps permet…} On expliquera pourquoi dans une chaîne de Markov
irréductible, un état est récurrent si et seulement si tous le sont, et que dans
ce cas, tous les états sont presque sûrement atteints. Ainsi, on a montré qu'un
ivrogne qui se déplace dans le plan peut être (presque) sûr de rentrer chez lui.

\newpage

\subsection{Inversion de Fourier et théorème de continuité de Lévy (en dimension 1)}

Notre but est de montrer, dans le cas $d = 1$ (mais toutes les preuves se
généralisent sans mal à $d$ quelconque) :

\begin{theorem}[Inversion de Fourier]
  Soit $f \in L^1(\R^d)$. Si $\hat{f} \in L^1(\R^d)$, on a pour presque
  tout $x \in \R^d$ :
\[ f(x) = \frac{1}{(2\pi)^d} \int_\R \hat{f}(\xi) e^{i\xi \cdot x} \,d\xi =
  \hat{\hat{f}}(-x). \]
\end{theorem}

En soi, la démonstration est un peu courte, donc on combine généralement ça avec
le calcul de la transformée de Fourier d'une gaussienne (résultat utilisé dans
la preuve). C'est utile pour faire rentrer le développement dans la leçon
\enquote{Illustrer par des exemples quelques méthodes de calcul d'intégrales …},
mais pour les autres circonstances, on propose ici un autre complément (suggéré
par N. Clozeau) : appliquer la formule d'inversion pour prouver le théorème de
continuité de Lévy (sur une variable aléatoire dans $\R$ quelconque, pas
forcément à densité !).

\paragraph{Préliminaires sur les gaussiennes}
On définit la gaussienne d'écart-type $\sigma > 0$ comme $g_\sigma : x \mapsto
(\sigma\sqrt{2\pi})^{-1}\exp(-x^2/2\sigma^2)$. On a $g_\sigma \in \S(\R)$, donc
elle est intégrable tout comme toutes ses dérivées.

\begin{lemma}
  Pour tout $f \in L^1(\R)$,
  $g_\sigma * f \underset{\sigma \to 0}{\longrightarrow} f$ dans $L^1(\R)$.
\end{lemma}
\begin{proof}
  Admis. Cette propriété découle du fait que les gaussiennes sont des
  approximations de l'unité.
\end{proof}

Attention, convergence $L^p$ n'entraîne pas convergence presque partout ! Par
contre, d'une suite qui converge dans $L^p$, on peut extraire une sous-suite qui
converge vers la même limite presque partout, d'où :
\begin{corollary}
  Il existe une suite $\sigma_n$ décroissante tendant vers 0 telle que
  $g_{\sigma_n} * f \rightarrow f$ p.p.
\end{corollary}
(Rappel : toute série absolument convergente dans $L^p$ converge p.p., ça
sert dans la preuve de complétude.)

\begin{proposition}[Transformée de Fourier des gaussiennes]
  $\displaystyle \widehat{g_\sigma}(\xi) =
  \exp\left(- \frac{\sigma^2 \xi^2}{2} \right) =
  \frac{\sqrt{2\pi}}{\sigma} g_{1/\sigma}(\xi)$.
\end{proposition}
\begin{proof}
  Il y en a plein, choisissez celle qui vous plaît. Une façon simple est
  d'utiliser le théorème de dérivation sous le signe intégral pour montrer que
  c'est une solution de l'équation différentielle $y' = -\sigma^2xy $. Comme
  $\widehat{g_\sigma}(0) = 1$ on peut parachuter la solution $\sqrt{2\pi}/\sigma
  \cdot g_{1/\sigma}$, Cauchy-Lipschitz linéaire assurant l'unicité.
\end{proof}

En itérant deux fois, on a bien $\widehat{\widehat{g_{\sigma}}} = 2\pi g_\sigma$
(le signe moins a disparu car $g_\sigma$ est paire) : la formule d'inversion de
Fourier est vérifiée par les gaussiennes.

\paragraph{Inversion de Fourier, cas général}

Soit $f \in L^1(\R)$ telle que $\hat{f} \in L^1(\R)$. On pose
\[ F_\sigma(x) = \int_\R \widehat{g_\sigma}(\xi)\hat{f}(\xi)e^{i\xi x} d\xi \]
Un calcul rapide (on écrit la formule intégrale pour $\hat{f}$, puis on utilise
Fubini) entraîne que
\[ F_\sigma(x) = \widehat{\widehat{g_\sigma}} * f(\xi) \]

On observe que $\widehat{g_\sigma} \longrightarrow 1$ ponctuellement quand
$\sigma \to 0$ ; en passant à la limite sur la suite $\sigma_n$ du lemme
préliminaire, on trouve l'égalité presque partout de la formule d'inversion de
Fourier. Pour ce faire on a besoin crucialement que $\hat{f} \in L^1(\R)$ pour
que le théorème de convergence dominée s'applique.

\paragraph{Application : théorème de continuité de Lévy} Rappelons tout d'abord
que pour vérifier une convergence en loi, il suffit de tester sur un ensemble de
fonctions dont l'adhérence contient $\Cf_c(\R)$, espace de fonctions continues
à support compact, alors que la définition de cette convergence fait intervenir
les fonctions continues bornées. C'est moralement un argument de densité mais
attention, $\Cf_c(\R)$ n'est pas dense dans $\Cf_b(\R)$ pour la norme uniforme !

\begin{theorem}[Lévy]
  Soit $X$ une variable aléatoire réelle de fonction caractéristique $\varphi$, et
  $(X_n)_{n \in \N}$ une suite de v.a. réelles dont on notera les fonctions
  caractéristiques $\varphi_n$ pour $n \in \N$. Alors $X_n \rightarrow X$ en loi si
  et seulement si $\varphi_n \rightarrow \varphi$ simplement.
\end{theorem}
\begin{proof}
  Le sens direct est évident, prouvons la réciproque. Soit $f \in
  \Cf^\infty_c(\R)$ (qui est bien dense dans $\Cf_c(\R)$), alors en particulier
  $f \in \S(\R)$ donc $f$ et $\hat{f}$ sont intégrables. Par conséquent, on peut
  écrire la formule d'inversion de Fourier sur $f$, puis prendre une espérance :
  \[ \forall n \in \N,\; \E[ f(X_n) ] = 
    \E\left[ \frac{1}{2\pi} \int_\R \hat{f}(\xi) e^{i\xi X_n}\,d\xi \right] =
    \frac{1}{2\pi} \int_\R \E\left[ \hat{f}(\xi) e^{i\xi X_n} \right] d\xi =
    \frac{1}{2\pi} \int_\R \hat{f}(\xi) \varphi_n(\xi)\, d\xi
  \]
  où l'on a interverti espérance et intégrale par le théorème de Fubini (à
  justifier). (Au fond, on n'a fait que constater que la transformation de
  Fourier préserve le produit scalaire.) On peut faire le même calcul pour
  $\E[f(X)]$, puis comme $|\varphi_n| \leq 1$ et $\hat{f} \in L^1(\R)$, le théorème
  de convergence dominée et notre  hypothèse de convergence des $\varphi_n$ nous
  donnent
  \[ \E[ f(X_n) ] \underset{n \to \infty}{\longrightarrow}
    \frac{1}{2\pi} \int_\R \hat{f}(\xi) \varphi(\xi)\, d\xi = \E[f(X)].  \]
\end{proof}

\newpage

\subsection{Théorème du point fixe de Brouwer $\Cf^1$}

Soit $n \geq 2$ un entier. On note $D^n$ la boule unité fermée de $\R^n$, et
$S^{n-1} = \partial D^n$ la sphère unité.

\begin{theorem}[Brouwer]
  Toute application $f \in \Cf^1(D^n, D^n)$ admet un point fixe.
\end{theorem}

\begin{remark}
  On en déduit le théorème pour $f \in \Cf^0(D^n, D^n)$.
\end{remark}
\begin{proof}
  On approxime $f$ par une suite de fonctions $\Cf^1$ qui convergent
  uniformément ; chacune admet un point fixe, et on extrait une sous-suite
  convergente.

  Attention : il faut s'assurer que les approximations de $f$ soient bien à
  valeur dans $D^n$ et non dans une boule de rayon $1+\varepsilon$.
\end{proof}

S'il existait un contre-exemple $f$ au théorème, alors on pourrait définir la
rétraction
\[ r : x \mapsto \frac{f(x) - x}{\|f(x) - x\|}\]
qui contredirait le lemme suivant :

\begin{lemma}[de non-rétraction $\Cf^1$]
  Il n'existe pas de fonction $r \in \Cf^1(D^n, S^{n-1})$ telle que
  $r\restriction_{S^{n-1}} = \mathrm{id}$.
\end{lemma}
\begin{remark}
En topologie algébrique, on prouve que $D^n$ et $S^{n-1}$ n'ont pas le même type
d'homotopie ; une conséquence est qu'il n'existe pas non plus de rétraction
$\Cf^0$.
\end{remark}

\begin{proof}[Preuve du lemme]
  Par l'absurde, soit $r$ un contre-exemple.  
  Posons, pour $t \in [0,1]$, $f_t = (1-t)\mathrm{id} + tr$, et définissons
  \[ P(t) = \int_{D^n} \det J_{f_t}(x)\,dx = \int_{D^n} \det ((1-t)I +
    tJ_r(x))\,dx \]
  où $J_r(x)$ désigne la matrice jacobienne de $r$ au point $x$.

  La seconde expression montre que la fonction $P$ est \emph{polynomiale}, ce
  qui résulte de la polynomialité du déterminant en développant l'intégrande.
  Comme $r(D^n)$ est d'intérieur vide, $J_r$ s'annule partout (contraposée du
  théorème d'inversion locale) donc $P(1) = 0$.

  Soit maintenant $t \in [0,1/(1+M)[$ où $M = \sup |||J_r|||$. Alors pour tout
  $x \in D^n$, $1-t > tM \geq |||tJ_r|||$, donc $J_{f_t}$ est inversible
  (propriété classique des algèbres de Banach). De plus, si $f_t(x) = f_t(y)$,
  alors
  \[(1-t)(x-y) = t(r(y) - r(x)) \quad \text{d'où} \quad
    (1-t)\|x-y\| = t\|r(x) - r(y)\| \leq tM\|x-y\| \]
  par inégalité des accroissements finis. Ceci contredit $1-t > tM$
  à moins que $\|x-y\| = 0$ : $f$ est donc injective.

  Le théorème d'inversion globale nous dit donc que $f_t$ est un difféomorphisme
  pour des petites valeurs de $t$. Ainsi, la formule de changement de variable
  s'applique immédiatement à la définition de $P(t)$ (ou presque ! modulo une
  valeur absolue qu'on évacue en vérifiant que l'intégrande est toujours
  positive), et donne $P(t) = \Vol(f_t(D^n))$.

  Que peut-on dire sur l'image de $f_t$ ? Tout d'abord, comme $D^n$ est compact,
  $f_t(D^n)$ est compacte, donc fermée dans $D^n$. $f_t(D^n)\setminus S^{n-1}$
  est donc un fermé relatif de la boule ouverte. Souvenons-nous maintenant que
  $r$ est une rétraction : on a donc $f_t(S^{n-1}) = S^{n-1}$, d'où par
  injectivité $f_t(D^n)\setminus S^{n-1} = f_t(D^n \setminus S^{n-1})$. Le
  membre de droite est un ouvert, car $D^n \setminus S^{n-1}$ est un ouvert de
  $\R^n$ et $f_t$ un difféomorphisme local. $f_t(D^n\setminus S^{n-1})$ est donc
  à la fois ouvert et fermé relativement à $D^n \setminus S^{n-1}$, et non vide,
  donc par connexité, on a finalement $f_t(D^n) = D^n$.

  Mais alors, la fonction polynomiale $P$ est constante égale à $\Vol(D^n)$ sur
  $[0,1/(1+M)[$, donc l'est partout. Or $\Vol(D^n) \neq 0$ et $P(1) = 0$,
  contradiction.
\end{proof}

\newpage

\subsection{Polynômes de Bernstein}

Référence : Zuily-Quéffélec.

\begin{theorem}[Bernstein]
  Soit $f \in \Cf([0,1], \R)$.
  
  Pour $n \in \N$ et $x \in \R$, on pose $B_n(x) = \E[f(X)]$ où $X \sim
  \textnormal{Binom}(n,x)$. Alors :
  \begin{enumerate}
  \item Pour tout $n \in \N$, $B_n : [0,1] \to \R$ est une fonction polynomiale.
    ($B_n$ est appelé le $n$-ième polynôme de Bernstein de $f$.)
  \item $\|B_n - f\|_\infty \underset{n \to \infty}{=} O\left(
      \omega_f(n^{-1/2}) \right)$.
  \end{enumerate}
\end{theorem}

On rappelle que
\[ \omega_f(h) = \sup_{|x-y| \leq h} |f(x) - f(y)| \]
est le \emph{module de continuité uniforme} de $f$.

\begin{corollary}[Weierstrass]
  Les fonctions polynomiales sont denses dans $\Cf([0,1])$.
\end{corollary}

Le corollaire découle directement du théorème de Heine, le point 1 du théorème
est trivial en écrivant la formule de l'espérance.

Démonstration du théorème :
\begin{enumerate}
\item À $x$ fixé, écrire $|B_n(x) - f(x)|$ comme une espérance, qu'on majore en
  utilisant $\omega_f$
\item Astuce : utiliser $\omega_f(\lambda h) \leq \lceil \lambda \rceil
  \omega_f(h)$ pour obtenir $\omega_f(n^{-1/2})$ fois un facteur probabiliste
\item Majorer l'espérance de ce facteur en faisant intervenir la variance
  (dépendante de $x$, paramètre de la loi binomiale)…
\item puis indépendamment de $x$, et c'est fini !
\end{enumerate}

TODO : optimalité de la borne par le théorème central limite.

Il faut bien connaître le théorème de Stone-Weierstrass plus général pour
répondre aux questions sur le développement.

\subsection{Méthode de Newton (lol)}

\subsection{Lemme de Morse}

Pour avoir une application aux formules de Taylor.

\section{Informatique}

\subsection{Théorème de Baker--Gill--Solovay}



\subsection{Minimisation par double renversement (avec complexité)}

Source : Sakarovitch.

Notons $D$ la déterminisation d'un automate, prenant en entrée un AFN et
renvoyant un AFDC, partie accessible de l'automate des parties. Notons $T$ la
transposition d'un automate, obtenue en renversant le sens des flèches. La
transposée d'un automate reconnaissant $L$ reconnaît $\tilde{L}$, langage miroir
de $L$.

\begin{algo}[Calcul d'un AFDC minimal à partir d'un AFN]
  Si $\mathcal{A}$ est un automate reconnaissant le langage $L$, $D \circ T
  \circ D \circ T(\mathcal{A})$ est un AFDC minimal reconnaissant $L$.
\end{algo}

Comme la dernière opération est une déterminisation, la sortie est bien un AFDC.
Le langage reconnu est préservé puisque $D$ le préserve et $T$ prend le miroir,
ce qui est involutif. Reste à prouver la minimalité.

\begin{lemma}[Brzozowski]
  Soit $\mathcal{B}$ un automate reconnaissant $L$, \emph{co-déterministe} et
  \emph{co-accessible} (autrement dit, dont la transposée est un AFD
  accessible). Soient $u$ et $v$ vérifiant $u^{-1}L = v^{-1}L$. Alors tout état
  atteignable en lisant $u$ l'est en lisant $v$.
\end{lemma}
\begin{proof}
  Soit $q$ atteignable à partir de $u$, $q$ est co-accessible donc il existe $w$
  atteignant l'unique état final à partir de $q$. $uw \in L$ donc $vw \in L$, et
  le seul chemin acceptant pour $vw$ doit passer par $q$ après avoir lu $v$ par
  co-déterminisime… Faire un dessin !
\end{proof}

Appliquons maintenant le lemme à $\mathcal{B} = T \circ D \circ T(\mathcal{A})$.
Si deux mots ont même résiduels, ils atteignent le même état dans l'automate des
parties de $\mathcal{B}$ en vertu du lemme. Il y a autant d'états que de
résiduels dans $D(\mathcal{B})$, ce dernier est donc minimal.

\begin{proposition}
  La complexité de cet algorithme est simplement exponentielle en le nombre
  d'états de l'automate d'entrée.
\end{proposition}

Pour une raison simple : la première fois qu'on déterminise, on peut avoir une
explosion exponentielle ; la seconde fois, c'est impossible puisque la taille de
la sortie est connue pour être celle d'un AFDC minimal !

TODO : réfléchir à la complexité précise de la déterminisation (avec taille de
l'alphabet en paramètre).

Pour avoir une minoration correspondante, on considère $L = X^{n-1}aX^*$ où $X =
\{a,b\}$ est l'alphabet. $L$ est reconnaissable par un AFD à $n+1$ états, et son
miroir a $2^n$ résiduels ! La minimisation ne fait que \emph{rajouter} un état
puits pour rendre l'automate complet.

\subsection{Union-find avec compression de chemin}

Trouvable sur CS Stack Exchange.

\[ \Phi(x) = \lambda \sum_{i=1}^n \log_2 w_i \]

On ne va étudier que Find (exercice : montrer que pour Union c'est bon).

\subsection{Tri par tas}

\subsection{Sélection en temps linéaire}

Avec une astuce pour rendre le truc plus rapide, merci Jill-Jênn !

\subsection{Réduction de 2SAT à la connexité forte}

\subsection{Rationalité des témoins en arithmétique de Presburger}

Soit $\phi(x_1,\ldots,x_k)$ une formule à $k$ variables libres de l'arithmétique
de Presburger, c'est-à-dire formée à partir des symboles $0$, $1$, $+$, $=$.
Soit $S_\phi$ son ensemble de témoins d'existence : $S_\phi = \{ (n_1, \ldots,
n_k) \in \N^k \mid \N \models \phi(n_1, \ldots, n_k) \}$. Définissons maintenant
le langage suivant :

\[ L_\phi = \left\{  \right\}\]
C'est compliqué à écrire formellement, mais ça représente juste des $k$-uplets
d'entiers codés en binaire. Comme la taille des entiers est non bornée et $k$
est fixe, on \enquote{transpose} les listes de listes de bits représentant
naturellement ces $k$-uplets pour avoir des mots sur un alphabet fini.

$L_\phi$ est un langage sur l'alphabet $\{0,1\}^k$.

\begin{proposition}
  $L_\phi$ est un langage rationnel, et de plus, on dispose d'une procédure
  effective pour construire un automate reconnaissant $L_\phi$ à partir de
  $\phi$.
\end{proposition}

\begin{corollary}
  L'arithmétique de Presburger est décidable.
\end{corollary}

\subsection{}



\section{Idées exclues}

\subsection{Unicité de la topologie de $\R$-EVT séparé en dimension finie}

(EVT = \emph{espace vectoriel topologique}, c'est-à-dire espace vectoriel muni
d'une topologie rendant continues les lois de compositions interne et externe.)

Évidemment, $\R$ est considéré avec sa topologie usuelle, et ça marche aussi
pour les $\C$-EVT.

\begin{theorem}
  Le $\R$-espace vectoriel $\R^n$ n'admet qu'une seule topologie de $\R$-EVT
  séparé, qui est la topologie produit.
\end{theorem}

\begin{remark}
  Les topologies non séparées sont obtenues comme topologie initiale d'une
  projection sur un quotient séparé et sont donc en bijection avec les
  sous-espaces vectoriels (prendre l'adhérence de $\{0\}$).
\end{remark}

Un résultat qui généralise l'équivalence des normes et clôt la question. Fait
dans les premières pages de Bourbaki, \emph{Espaces vectoriels topologiques},
dans le cadre général des corps valués non discrets.

\subsection{Lemme de Hensel, ou méthode de Newton $p$-adique}

Violemment hors-programme, dommage, c'est plus original que la méthode de Newton
usuelle et c'est de la jolie algèbre en plus… Un PDF de Keith Conrad raconte ça
super bien.

\begin{definition}
  On appelle \emph{entier $p$-adique} une suite $(a_n)_{n \in \N^*}$
  avec $a_n \in \Z/p^n\Z$ et $\pi_n(a_{n+1}) = a_n$ pour $n \in \N^*$,
  où $\pi_n : \Z/p^{n+1}\Z \to \Z/p^n\Z$ est la projection canonique.
\end{definition}
\begin{proposition}
  Les entiers $p$-adiques forment un sous-anneau de
  $\prod_{n \in \N^*} \Z/p^n\Z$, de caractéristique nulle. Cet anneau
  est noté $\Z_p$.
\end{proposition}

\begin{definition}
  Le \emph{corps des nombres $p$-adiques} $\Q_p$ est le complété de
  $\Q$ pour la distance $d_p(x,y) = p^{-v_p(x-y)}$.
\end{definition}
\begin{proposition}
  La boule fermée de centre 0 et de rayon 1 dans $\Q_p$ est un
  sous-anneau isomorphe à $\Z_p$.
\end{proposition}

\begin{lemma}[Hensel]
  Soient $f \in \Z_p[X]$ et $a \in \Z/p\Z$ tels que dans $\Z/p\Z$, on
  ait $f(a) = 0$ et $f'(a) \neq 0$. Alors il existe un unique
  $\alpha \in \Z_p$ tel que $f(\alpha) = 0$ et dont la classe dans
  $\Z/p\Z$ soit $a$.
\end{lemma}

\begin{corollary}
  Soient $f \in \Z[X]$ et $a \in \Z$ tels que $f(a) \equiv 0 \mod p$
  et $f'(a) \not\equiv 0 \mod p$. Alors pour tout $n \in \N^*$, il
  existe $\alpha \in \Z$ tel que $f(\alpha) \equiv 0 \mod p^n$ et
  $\alpha \equiv a \mod p$.
\end{corollary}

On a deux procédés d'itération légèrement différents pour relever des solutions
dans un $\Z/p^n\Z$ plus grand : l'un est la méthode de Newton, l'autre ressemble
à la preuve du théorème d'inversion locale.

\subsection{Schéma de réflexion de Kreisel}

\begin{theorem}[Kreisel]
  Soit $T$ un sous-système fini de l'arithmétique de Peano. Pour toute formule
  close $F$, AP prouve : \enquote{$F \text{ prouvable dans } T \Rightarrow F$}.
\end{theorem}
Note : dans la formule $\phi$ dont il est affirmé que $AP \vdash \phi$, à gauche
de $\Rightarrow$, on a un prédicat de prouvabilité appliqué au code de Gödel de
$F$, et à droite, on a vraiment $F$.
\begin{corollary}
  L'arithmétique de Peano prouve la cohérence de ses sous-systèmes finis, et
  n'est donc pas finiment axiomatisable.
\end{corollary}

D'abord, on peut se ramener au cas où $T = \emptyset$. Ensuite, essentiellement,
on veut montrer naïvement que $F$ prouvable $\Rightarrow$ $F$ vraie par
induction sur les règles logiques, qui préservent la vérité. Comme les formules
apparaissant dans une preuve sans coupures de $F$ sont de complexité logique
bornée par celle de $F$, on peut définir un prédicat de vérité borné qui fait
marcher ça, et de sorte que \enquote{$F$ vraie} soit équivalent à $F$.

Souci majeur : les détails sont impossibles à expliciter en 15 minutes, et la
preuve repose sur la possibilité de raisonner de façon interne dans AP, ce
pourquoi il faut déjà avoir une bonne intuition de quels principes logiques y
sont autorisés (les fonctions récursives sont définissables, l'induction
structurelle est valide…) car cela devient imbuvable sans un recours intensif à
l'agitage de mains.

Je ne connais pas d'autre référence \enquote{livre de cours} que Le Point
aveugle pour ce théorème…

\subsection{Algorithme de Hirschberg}

Une superbe astuce qui consiste à utiliser un diviser-pour-régner afin de
baisser la complexité spatiale d'un algorithme de programmation dynamique,
appliquée au problème de la distance d'édition. On utilise la programmation
dynamique pour calculer le point de délimitation entre les deux sous-problèmes
récursifs.

C'est parfaitement au programme de l'agrégation, mais c'est trop long…

\end{document}
